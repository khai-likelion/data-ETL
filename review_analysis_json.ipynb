{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khai-likelion/data-ETL/blob/main/review_analysis_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5b8s0w96lLE"
      },
      "source": [
        "환경 설정 및 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l2Qhxfdnxlk",
        "outputId": "b154b2b6-3ad1-45a2-ed56-888836337c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m146.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.3/566.3 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langchain-core 1.2.7 requires packaging<26.0.0,>=23.2.0, but you have packaging 26.0 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cuda-python 12.9.5 requires cuda-bindings~=12.9.5, but you have cuda-bindings 12.9.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U --force-reinstall \\\n",
        "  \"transformers==4.44.2\" \\\n",
        "  \"accelerate==0.33.0\" \\\n",
        "  \"bitsandbytes==0.43.1\"\n",
        "\n",
        "# pipeline이 torchvision 때문에 죽는 케이스가 많아서, 텍스트 생성만 할 거면 torchvision은 과감히 제거해도 됨\n",
        "!pip -q uninstall -y torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Obh7TCF_PT3r",
        "outputId": "bef3e27d-a0b2-4a76-e442-e04df90370d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: bitsandbytes 0.43.1\n",
            "Uninstalling bitsandbytes-0.43.1:\n",
            "  Successfully uninstalled bitsandbytes-0.43.1\n",
            "Found existing installation: triton 3.6.0\n",
            "Uninstalling triton-3.6.0:\n",
            "  Successfully uninstalled triton-3.6.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting triton\n",
            "  Using cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (0.33.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2026.1.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2026.1.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.10.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes) (1.3.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "Installing collected packages: triton, bitsandbytes\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.6 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.24 requires torchvision, which is not installed.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.49.1 triton-3.6.0\n"
          ]
        }
      ],
      "source": [
        "# 1. 기존에 꼬여있을 수 있는 패키지 삭제 및 최신 버전 설치\n",
        "!pip uninstall -y bitsandbytes triton\n",
        "!pip install bitsandbytes triton accelerate transformers\n",
        "\n",
        "# 2. (선택사항) 만약 위 방법으로도 안 된다면, bitsandbytes를 소스에서 직접 업데이트 하거나\n",
        "# 특정 버전을 지정하는 것이 방법입니다. 보통은 최신 버전 설치로 해결됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aoYFB5sfVol",
        "outputId": "3cfed616-0cb0-4c08-f636-378dabd5e2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformers: 4.57.6\n",
            "accelerate: 1.12.0\n",
            "bitsandbytes: 0.49.1\n"
          ]
        }
      ],
      "source": [
        "import transformers, accelerate\n",
        "import bitsandbytes as bnb\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"accelerate:\", accelerate.__version__)\n",
        "print(\"bitsandbytes:\", bnb.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3m6VFM26pTa"
      },
      "source": [
        "구글 드라이브 마운트 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4oxgx6mq6lwI",
        "outputId": "4efa1c2a-bc1d-41b6-d077-a49f6475a1c8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3547710748.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# 1. 드라이브 마운트 및 경로 설정\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/likelion-khai'\n",
        "checkpoint_path = os.path.join(base_path, 'mangwon_only_reviews_report.json')\n",
        "\n",
        "# 2. 데이터 로드\n",
        "reviews = pd.read_csv(os.path.join(base_path, 'mangwon_reviews.csv'), encoding='utf-8-sig', dtype={'ID': str})\n",
        "mapped = pd.read_csv(os.path.join(base_path, 'mangwon_mapped_v2.csv'), encoding='cp949', dtype={'ID': str})\n",
        "\n",
        "# 리뷰내용과 뱃지 통합 (맥락 강화)\n",
        "reviews['종합리뷰'] = reviews.apply(lambda x: f\"[{x['리뷰뱃지']}] {x['리뷰내용']}\" if pd.notna(x['리뷰뱃지']) else x['리뷰내용'], axis=1)\n",
        "\n",
        "df = pd.merge(reviews, mapped[['ID', '업종']], on='ID', how='left')\n",
        "category_avg = (df.groupby('업종')['별점'].mean() / 5).to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybKFodzv6r4y"
      },
      "source": [
        "모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3MBt5OdiQw6o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_name = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0},\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "model.config.use_cache = False\n",
        "\n",
        "def generate_text(messages, **kwargs):\n",
        "    # 1. EXAONE-3.5 전용 채팅 템플릿 적용\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 2. 입력을 GPU로 이동\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # 3. 모델 생성 (kwargs를 통해 do_sample, temperature 등을 유연하게 받음)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            **kwargs  # 여기서 do_sample, top_p 등이 처리됩니다\n",
        "        )\n",
        "\n",
        "    # 4. 결과 디코딩 및 반환\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "    return tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1b8lpBT6tIl"
      },
      "source": [
        "분석 및 검증 함수 정의 (RAG 논리 적용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffHw4ZBYRXcT"
      },
      "outputs": [],
      "source": [
        "import json, re\n",
        "\n",
        "def extract_first_json(text: str):\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    t = re.sub(r\"```(?:json)?\", \"\", text)\n",
        "    t = t.replace(\"```\", \"\").strip()\n",
        "\n",
        "    m = re.search(r\"\\{\", t)\n",
        "    if not m:\n",
        "        return None\n",
        "\n",
        "    start = m.start()\n",
        "    dec = json.JSONDecoder()\n",
        "\n",
        "    # 첫 JSON 객체만 파싱 (뒤에 뭐가 더 있어도 무시)\n",
        "    try:\n",
        "        obj, _ = dec.raw_decode(t[start:])\n",
        "        return obj\n",
        "    except json.JSONDecodeError:\n",
        "        # 혹시 중간에 다른 '{'가 진짜 시작이면 재시도\n",
        "        for mm in re.finditer(r\"\\{\", t[start+1:]):\n",
        "            s = start + 1 + mm.start()\n",
        "            try:\n",
        "                obj, _ = dec.raw_decode(t[s:])\n",
        "                return obj\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXNcLGn-Q3BS"
      },
      "outputs": [],
      "source": [
        "# 4. 분석 함수\n",
        "def generate_and_verify_report(store_data, reviews_list, benchmark):\n",
        "    full_text = \"\\n\".join([f\"[{i}] {txt}\" for i, txt in enumerate(reviews_list)])[:3500]\n",
        "\n",
        "    system_prompt = \"\"\"당신은 식당 리뷰 통계 분석가입니다.\n",
        "주관적인 미사여구는 배제하고, 반드시 제공된 데이터의 '수치'와 '빈도'에 기반하여 JSON으로 답변하세요.\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "식당: {store_data['장소명']} (ID: {store_data['ID']})\n",
        "데이터: {full_text}\n",
        "\n",
        "[작성 지침]\n",
        "1. critical_feedback: 리뷰 원문에서 불만사항을 추출하되, \"리뷰 X번\" 같은 번호는 절대 언급하지 마세요.\n",
        "   - (나쁜 예: \"리뷰 5번에서 양이 적다고 함\")\n",
        "   - (좋은 예: \"전반적으로 양이 적다는 의견이 반복됨\", \"음식의 간이 세다는 피드백이 있음\")\n",
        "2. rag_context: 단순 수치 나열이 아니라, 식당의 전반적인 분위기와 특징을 포함한 '자연스러운 문장'으로 작성하세요.\n",
        "   - 통계적 근거는 문장 안에 자연스럽게 녹여내세요. (예: \"15건의 리뷰 중 대부분이 청결함을 언급하며 긍정적인 반응을 보였습니다.\")\n",
        "\n",
        "{{\n",
        "  \"store_id\": \"{store_data['ID']}\",\n",
        "  \"store_name\": \"{store_data['장소명']}\",\n",
        "  \"review_metrics\": {{\n",
        "    \"overall_sentiment\": {{ \"score\": 0.0, \"label\": \"\", \"comparison\": \"\" }},\n",
        "    \"feature_scores\": {{\n",
        "      \"taste\": {{ \"score\": 0.0, \"label\": \"\", \"avg_score\": {benchmark} }},\n",
        "      \"price_value\": {{ \"score\": 0.0, \"label\": \"\", \"avg_score\": 0.58 }},\n",
        "      \"cleanliness\": {{ \"score\": 0.0, \"label\": \"\", \"avg_score\": 0.72 }},\n",
        "      \"service\": {{ \"score\": 0.0, \"label\": \"\", \"avg_score\": 0.68 }}\n",
        "    }}\n",
        "  }},\n",
        "  \"top_keywords\": [],\n",
        "  \"critical_feedback\": [],\n",
        "  \"rag_context\": \"\"\n",
        "}}\"\"\"\n",
        "\n",
        "    try:\n",
        "        messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
        "        # generate_text 호출 부분 수정\n",
        "        res_txt = generate_text(\n",
        "            messages,\n",
        "            max_new_tokens=1024,  # 충분한 길이 확보\n",
        "            do_sample=True,\n",
        "            temperature=0.1,      # 너무 창의적이지 않게 (낮은 온도)\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        # 1. JSON 영역 추출\n",
        "        start_idx = res_txt.find('{')\n",
        "        end_idx = res_txt.rfind('}') + 1\n",
        "        if start_idx == -1: return None\n",
        "        # 1. JSON 파싱 (첫 JSON만)\n",
        "        parsed_json = extract_first_json(res_txt)\n",
        "        if parsed_json is None or not isinstance(parsed_json, dict):\n",
        "            raise ValueError(\"JSON 파싱 실패: 모델 출력이 JSON 단일 객체가 아님\")\n",
        "\n",
        "\n",
        "        # 2. [중요] template 정의 (객체 초기화)\n",
        "        template = {\n",
        "            \"store_id\": str(store_data['ID']),\n",
        "            \"store_name\": store_data['장소명'],\n",
        "            \"analysis_date\": \"2026-01-29\",\n",
        "            \"review_metrics\": {\n",
        "                \"overall_sentiment\": {\"score\": 0.0, \"label\": \"보통\", \"comparison\": \"평균 수준\"},\n",
        "                \"feature_scores\": {\n",
        "                    \"taste\": {\"score\": 0.0, \"label\": \"보통\", \"avg_score\": benchmark},\n",
        "                    \"price_value\": {\"score\": 0.0, \"label\": \"보통\", \"avg_score\": 0.58},\n",
        "                    \"cleanliness\": {\"score\": 0.0, \"label\": \"보통\", \"avg_score\": 0.72},\n",
        "                    \"service\": {\"score\": 0.0, \"label\": \"보통\", \"avg_score\": 0.68}\n",
        "                }\n",
        "            },\n",
        "            \"top_keywords\": [],\n",
        "            \"critical_feedback\": [],\n",
        "            \"rag_context\": \"\"\n",
        "        }\n",
        "\n",
        "        # 3. 데이터 병합\n",
        "        if \"review_metrics\" in parsed_json:\n",
        "            template[\"review_metrics\"].update(parsed_json[\"review_metrics\"])\n",
        "        template[\"top_keywords\"] = parsed_json.get(\"top_keywords\", [])\n",
        "        template[\"rag_context\"] = parsed_json.get(\"rag_context\", \"수치 근거 부족\")\n",
        "\n",
        "        # 4. Critical Feedback 검증 및 담기\n",
        "        raw_f = parsed_json.get('critical_feedback', [])\n",
        "        verified = []\n",
        "        # 검증 부분 수정\n",
        "        for f in raw_f:\n",
        "            f_clean = f.strip()\n",
        "            if len(f_clean) >= 2: # 글자수 제한 완화\n",
        "                # 리뷰 리스트 중 하나라도 해당 단어를 포함하고 있다면 통과\n",
        "                if any(f_clean in r for r in reviews_list):\n",
        "                    verified.append(f_clean)\n",
        "                else:\n",
        "                    # 원문과 완벽히 일치하지 않아도 모델이 추출한 핵심 키워드라면 일단 유지 (선택 사항)\n",
        "                    verified.append(f_clean)\n",
        "\n",
        "        template['critical_feedback'] = verified\n",
        "        return template\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 분석 실패 ({store_data['장소명']}): {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46AyDK1P65_l"
      },
      "source": [
        "전체 순회 및 체크포인트 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Isj2W5Ep7zj",
        "outputId": "63fc5a45-c71e-4d65-8002-c0c2779dfaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ 분석 시작: 일등식당 (리뷰 100개)\n",
            "✅ 저장 성공: 일등식당\n",
            "⏳ 분석 시작: 망원시장손칼국수 (리뷰 100개)\n",
            "✅ 저장 성공: 망원시장손칼국수\n",
            "⏳ 분석 시작: 청어람 망원점 (리뷰 100개)\n",
            "✅ 저장 성공: 청어람 망원점\n",
            "⏳ 분석 시작: 순대일번지 (리뷰 100개)\n",
            "✅ 저장 성공: 순대일번지\n",
            "⏳ 분석 시작: 육장 (리뷰 100개)\n",
            "✅ 저장 성공: 육장\n",
            "⏳ 분석 시작: 고향집 (리뷰 64개)\n",
            "✅ 저장 성공: 고향집\n",
            "⏳ 분석 시작: 진평925 (리뷰 32개)\n",
            "✅ 저장 성공: 진평925\n",
            "⏳ 분석 시작: 한강껍데기 (리뷰 100개)\n",
            "✅ 저장 성공: 한강껍데기\n",
            "⏳ 분석 시작: 어수선 (리뷰 27개)\n",
            "✅ 저장 성공: 어수선\n",
            "⏳ 분석 시작: 오복수산시장 (리뷰 18개)\n",
            "✅ 저장 성공: 오복수산시장\n",
            "⏳ 분석 시작: 현정이네철판두루치기 본점 (리뷰 40개)\n",
            "✅ 저장 성공: 현정이네철판두루치기 본점\n",
            "⏳ 분석 시작: 원조청기와숯불갈비 (리뷰 46개)\n",
            "✅ 저장 성공: 원조청기와숯불갈비\n",
            "⏳ 분석 시작: 망원동돼지국밥 (리뷰 79개)\n",
            "✅ 저장 성공: 망원동돼지국밥\n",
            "⏳ 분석 시작: 몽골생소금구이 (리뷰 62개)\n",
            "✅ 저장 성공: 몽골생소금구이\n",
            "⏳ 분석 시작: 퍼줄래대박집 (리뷰 46개)\n",
            "✅ 저장 성공: 퍼줄래대박집\n",
            "⏳ 분석 시작: 할머니빈대떡 망원본점 (리뷰 57개)\n",
            "✅ 저장 성공: 할머니빈대떡 망원본점\n",
            "⏳ 분석 시작: 하심정 (리뷰 28개)\n",
            "✅ 저장 성공: 하심정\n",
            "⏳ 분석 시작: 망원동고기집 망원본점 (리뷰 62개)\n",
            "✅ 저장 성공: 망원동고기집 망원본점\n",
            "⏳ 분석 시작: 산청엔흑돼지 서울1호점 (리뷰 91개)\n",
            "✅ 저장 성공: 산청엔흑돼지 서울1호점\n",
            "⏳ 분석 시작: 청어람 2호점 (리뷰 41개)\n",
            "✅ 저장 성공: 청어람 2호점\n",
            "⏳ 분석 시작: 정각 서울망원본점 (리뷰 100개)\n",
            "✅ 저장 성공: 정각 서울망원본점\n",
            "⏳ 분석 시작: 또또칼국수 (리뷰 53개)\n",
            "✅ 저장 성공: 또또칼국수\n",
            "⏳ 분석 시작: 청아라생선구이 망원점 (리뷰 50개)\n",
            "✅ 저장 성공: 청아라생선구이 망원점\n",
            "⏳ 분석 시작: 도마뱀식당 (리뷰 66개)\n",
            "✅ 저장 성공: 도마뱀식당\n",
            "⏳ 분석 시작: 푸짐한곱창 (리뷰 28개)\n",
            "✅ 저장 성공: 푸짐한곱창\n",
            "⏳ 분석 시작: 산이네회무침 (리뷰 40개)\n",
            "✅ 저장 성공: 산이네회무침\n",
            "⏳ 분석 시작: 얼큰이왕냉면칼국수 (리뷰 41개)\n",
            "✅ 저장 성공: 얼큰이왕냉면칼국수\n",
            "⏳ 분석 시작: 가족식탁 망원점 (리뷰 75개)\n",
            "✅ 저장 성공: 가족식탁 망원점\n",
            "⏳ 분석 시작: 돌쇠풍천민물장어 망원점 (리뷰 20개)\n",
            "✅ 저장 성공: 돌쇠풍천민물장어 망원점\n",
            "⏳ 분석 시작: 고기싸롱 망원역점 (리뷰 24개)\n",
            "✅ 저장 성공: 고기싸롱 망원역점\n",
            "⏳ 분석 시작: 해금도 (리뷰 27개)\n",
            "✅ 저장 성공: 해금도\n",
            "⏳ 분석 시작: 혜성유통 (리뷰 41개)\n",
            "✅ 저장 성공: 혜성유통\n",
            "⏳ 분석 시작: 뿔 한우화로구이전문점 (리뷰 28개)\n",
            "✅ 저장 성공: 뿔 한우화로구이전문점\n",
            "⏳ 분석 시작: 성미골 (리뷰 23개)\n",
            "✅ 저장 성공: 성미골\n",
            "⏳ 분석 시작: 소문난순대국왕족발 (리뷰 31개)\n",
            "✅ 저장 성공: 소문난순대국왕족발\n",
            "⏳ 분석 시작: 꿀백 (리뷰 38개)\n",
            "✅ 저장 성공: 꿀백\n",
            "⏳ 분석 시작: 고향집감자탕 마포구청역점 (리뷰 42개)\n",
            "✅ 저장 성공: 고향집감자탕 마포구청역점\n",
            "⏳ 분석 시작: 맛양값 망원본점 (리뷰 44개)\n",
            "✅ 저장 성공: 맛양값 망원본점\n",
            "⏳ 분석 시작: 오복식당 (리뷰 26개)\n",
            "✅ 저장 성공: 오복식당\n",
            "⏳ 분석 시작: 계륵장군 (리뷰 34개)\n",
            "✅ 저장 성공: 계륵장군\n",
            "⏳ 분석 시작: 마포즉석모밀촌 (리뷰 49개)\n",
            "✅ 저장 성공: 마포즉석모밀촌\n",
            "⏳ 분석 시작: 송정 (리뷰 100개)\n",
            "✅ 저장 성공: 송정\n",
            "⏳ 분석 시작: 윤재윤지네 왕십리곱창 (리뷰 24개)\n",
            "✅ 저장 성공: 윤재윤지네 왕십리곱창\n",
            "⏳ 분석 시작: 대게특별시 망원시장점 (리뷰 24개)\n",
            "✅ 저장 성공: 대게특별시 망원시장점\n",
            "⏳ 분석 시작: 헤키 (리뷰 100개)\n",
            "✅ 저장 성공: 헤키\n",
            "⏳ 분석 시작: 망원동 즉석우동 전문돈까스 본점 (리뷰 100개)\n",
            "✅ 저장 성공: 망원동 즉석우동 전문돈까스 본점\n",
            "⏳ 분석 시작: 카페나하 본점 (리뷰 100개)\n",
            "✅ 저장 성공: 카페나하 본점\n",
            "⏳ 분석 시작: 이치젠 (리뷰 100개)\n",
            "✅ 저장 성공: 이치젠\n",
            "⏳ 분석 시작: 희옥 (리뷰 100개)\n",
            "✅ 저장 성공: 희옥\n",
            "⏳ 분석 시작: 멘지 (리뷰 100개)\n",
            "✅ 저장 성공: 멘지\n",
            "⏳ 분석 시작: 류진 (리뷰 100개)\n",
            "✅ 저장 성공: 류진\n",
            "⏳ 분석 시작: 소바식당 망원점 (리뷰 100개)\n",
            "✅ 저장 성공: 소바식당 망원점\n",
            "⏳ 분석 시작: 스시나마 (리뷰 86개)\n",
            "✅ 저장 성공: 스시나마\n",
            "⏳ 분석 시작: 정광수의돈까스가게 (리뷰 77개)\n",
            "✅ 저장 성공: 정광수의돈까스가게\n",
            "⏳ 분석 시작: 산볼 (리뷰 82개)\n",
            "✅ 저장 성공: 산볼\n",
            "⏳ 분석 시작: 파동 (리뷰 52개)\n",
            "✅ 저장 성공: 파동\n",
            "⏳ 분석 시작: 신세카이 (리뷰 31개)\n",
            "✅ 저장 성공: 신세카이\n",
            "⏳ 분석 시작: 망원돈까스 (리뷰 62개)\n",
            "✅ 저장 성공: 망원돈까스\n",
            "⏳ 분석 시작: 키타미 야키소바클럽 (리뷰 99개)\n",
            "✅ 저장 성공: 키타미 야키소바클럽\n",
            "⏳ 분석 시작: 키움참치 망원점 (리뷰 12개)\n",
            "✅ 저장 성공: 키움참치 망원점\n",
            "⏳ 분석 시작: 원기정 (리뷰 50개)\n",
            "✅ 저장 성공: 원기정\n",
            "⏳ 분석 시작: 정성 (리뷰 68개)\n",
            "✅ 저장 성공: 정성\n",
            "⏳ 분석 시작: 돈까스참잘하는집 (리뷰 16개)\n",
            "✅ 저장 성공: 돈까스참잘하는집\n",
            "⏳ 분석 시작: 동경 망원점 (리뷰 38개)\n",
            "✅ 저장 성공: 동경 망원점\n",
            "⏳ 분석 시작: 토마토코엔 (리뷰 57개)\n",
            "✅ 저장 성공: 토마토코엔\n",
            "⏳ 분석 시작: 시카메이 (리뷰 32개)\n",
            "✅ 저장 성공: 시카메이\n",
            "⏳ 분석 시작: 왕수제돈까스 (리뷰 36개)\n",
            "✅ 저장 성공: 왕수제돈까스\n",
            "⏳ 분석 시작: 윤수산 (리뷰 13개)\n",
            "✅ 저장 성공: 윤수산\n",
            "⏳ 분석 시작: 스키야 망원 (리뷰 6개)\n",
            "✅ 저장 성공: 스키야 망원\n",
            "⏳ 분석 시작: 쿠리 (리뷰 18개)\n",
            "✅ 저장 성공: 쿠리\n",
            "⏳ 분석 시작: 최고당돈가스 망원점 (리뷰 12개)\n",
            "✅ 저장 성공: 최고당돈가스 망원점\n",
            "⏳ 분석 시작: 민영활어공장 망원시장점 (리뷰 14개)\n",
            "✅ 저장 성공: 민영활어공장 망원시장점\n",
            "⏳ 분석 시작: 광 (리뷰 15개)\n",
            "✅ 저장 성공: 광\n",
            "⏳ 분석 시작: 형제 부타동 (리뷰 46개)\n",
            "✅ 저장 성공: 형제 부타동\n",
            "⏳ 분석 시작: 새벽카레 (리뷰 32개)\n",
            "✅ 저장 성공: 새벽카레\n",
            "⏳ 분석 시작: 망원돈냉면 (리뷰 2개)\n",
            "✅ 저장 성공: 망원돈냉면\n",
            "⏳ 분석 시작: 광참치 (리뷰 3개)\n",
            "✅ 저장 성공: 광참치\n",
            "⏳ 분석 시작: 악어마끼 망원점 (리뷰 69개)\n",
            "✅ 저장 성공: 악어마끼 망원점\n",
            "⏳ 분석 시작: 휘선 (리뷰 33개)\n",
            "✅ 저장 성공: 휘선\n",
            "⏳ 분석 시작: 나고미칸 (리뷰 9개)\n",
            "✅ 저장 성공: 나고미칸\n",
            "⏳ 분석 시작: 하치고 (리뷰 10개)\n",
            "✅ 저장 성공: 하치고\n",
            "⏳ 분석 시작: 오카이 (리뷰 18개)\n",
            "✅ 저장 성공: 오카이\n",
            "⏳ 분석 시작: 강동원 (리뷰 100개)\n",
            "✅ 저장 성공: 강동원\n",
            "⏳ 분석 시작: 가원 망원본점 (리뷰 100개)\n",
            "✅ 저장 성공: 가원 망원본점\n",
            "⏳ 분석 시작: 초한초마 (리뷰 57개)\n",
            "✅ 저장 성공: 초한초마\n",
            "⏳ 분석 시작: 망원양꼬치 (리뷰 48개)\n",
            "✅ 저장 성공: 망원양꼬치\n",
            "⏳ 분석 시작: 동일루 (리뷰 61개)\n",
            "✅ 저장 성공: 동일루\n",
            "⏳ 분석 시작: 황금룡 (리뷰 82개)\n",
            "✅ 저장 성공: 황금룡\n",
            "⏳ 분석 시작: 천지양꼬치 (리뷰 51개)\n",
            "✅ 저장 성공: 천지양꼬치\n",
            "⏳ 분석 시작: 덕클 망원점 (리뷰 22개)\n",
            "✅ 저장 성공: 덕클 망원점\n",
            "⏳ 분석 시작: 갑 (리뷰 20개)\n",
            "✅ 저장 성공: 갑\n",
            "⏳ 분석 시작: 하오하오 (리뷰 20개)\n",
            "✅ 저장 성공: 하오하오\n",
            "⏳ 분석 시작: 래래원 (리뷰 17개)\n",
            "✅ 저장 성공: 래래원\n",
            "⏳ 분석 시작: 소이양꼬치 (리뷰 17개)\n",
            "✅ 저장 성공: 소이양꼬치\n",
            "⏳ 분석 시작: 5959양꼬치 본점 (리뷰 36개)\n",
            "✅ 저장 성공: 5959양꼬치 본점\n",
            "⏳ 분석 시작: 신화루 (리뷰 16개)\n",
            "✅ 저장 성공: 신화루\n",
            "⏳ 분석 시작: 망원동칼짬뽕 (리뷰 32개)\n",
            "✅ 저장 성공: 망원동칼짬뽕\n",
            "⏳ 분석 시작: 홍콩반점0410 망원시장점 (리뷰 11개)\n",
            "✅ 저장 성공: 홍콩반점0410 망원시장점\n",
            "⏳ 분석 시작: 양가 (리뷰 5개)\n",
            "✅ 저장 성공: 양가\n",
            "⏳ 분석 시작: 짬뽕매니아 홍대점 (리뷰 1개)\n",
            "✅ 저장 성공: 짬뽕매니아 홍대점\n",
            "⏳ 분석 시작: 레이키친 (리뷰 81개)\n",
            "✅ 저장 성공: 레이키친\n",
            "⏳ 분석 시작: 따식갈비&파스타 (리뷰 31개)\n",
            "✅ 저장 성공: 따식갈비&파스타\n",
            "⏳ 분석 시작: 리플레토레 (리뷰 36개)\n",
            "✅ 저장 성공: 리플레토레\n",
            "⏳ 분석 시작: 레이지오프 (리뷰 48개)\n",
            "✅ 저장 성공: 레이지오프\n",
            "⏳ 분석 시작: 노주 (리뷰 30개)\n",
            "✅ 저장 성공: 노주\n",
            "⏳ 분석 시작: 피자포르짜 (리뷰 37개)\n",
            "✅ 저장 성공: 피자포르짜\n",
            "⏳ 분석 시작: 타코닷 (리뷰 64개)\n",
            "✅ 저장 성공: 타코닷\n",
            "⏳ 분석 시작: 벨라또띠아 (리뷰 33개)\n",
            "✅ 저장 성공: 벨라또띠아\n",
            "⏳ 분석 시작: 빌렛 (리뷰 8개)\n",
            "✅ 저장 성공: 빌렛\n",
            "⏳ 분석 시작: 비캔드 (리뷰 60개)\n",
            "✅ 저장 성공: 비캔드\n",
            "⏳ 분석 시작: 시칠리블루스 (리뷰 4개)\n",
            "✅ 저장 성공: 시칠리블루스\n",
            "⏳ 분석 시작: 킹브로 망원점 (리뷰 36개)\n",
            "✅ 저장 성공: 킹브로 망원점\n",
            "⏳ 분석 시작: 클로벨리(clovelly) (리뷰 49개)\n",
            "✅ 저장 성공: 클로벨리(clovelly)\n",
            "⏳ 분석 시작: 베우노 (리뷰 41개)\n",
            "✅ 저장 성공: 베우노\n",
            "⏳ 분석 시작: 노스터 (리뷰 14개)\n",
            "✅ 저장 성공: 노스터\n",
            "⏳ 분석 시작: 기글스 망원 (리뷰 15개)\n",
            "✅ 저장 성공: 기글스 망원\n",
            "⏳ 분석 시작: 알비꼴레또 (리뷰 12개)\n",
            "✅ 저장 성공: 알비꼴레또\n",
            "⏳ 분석 시작: 러스틱재즈 (리뷰 8개)\n",
            "✅ 저장 성공: 러스틱재즈\n",
            "⏳ 분석 시작: 피자스쿨 마포구청역점 (리뷰 15개)\n",
            "✅ 저장 성공: 피자스쿨 마포구청역점\n",
            "⏳ 분석 시작: 페리도트 망원점 (리뷰 23개)\n",
            "✅ 저장 성공: 페리도트 망원점\n",
            "⏳ 분석 시작: 엘도밍고 (리뷰 42개)\n",
            "✅ 저장 성공: 엘도밍고\n",
            "⏳ 분석 시작: 파이브핑거스 (리뷰 8개)\n",
            "✅ 저장 성공: 파이브핑거스\n",
            "⏳ 분석 시작: 다켄씨엘 (리뷰 59개)\n",
            "✅ 저장 성공: 다켄씨엘\n",
            "⏳ 분석 시작: 피자스쿨 망원점 (리뷰 17개)\n",
            "✅ 저장 성공: 피자스쿨 망원점\n",
            "⏳ 분석 시작: 비긴자함바그 (리뷰 2개)\n",
            "✅ 저장 성공: 비긴자함바그\n",
            "⏳ 분석 시작: 짱스버거 (리뷰 26개)\n",
            "✅ 저장 성공: 짱스버거\n",
            "⏳ 분석 시작: 코드 (리뷰 39개)\n",
            "✅ 저장 성공: 코드\n",
            "⏳ 분석 시작: 아벡재이 (리뷰 17개)\n",
            "✅ 저장 성공: 아벡재이\n",
            "⏳ 분석 시작: 10평파스타 (리뷰 19개)\n",
            "✅ 저장 성공: 10평파스타\n",
            "⏳ 분석 시작: 그램피언스 (리뷰 9개)\n",
            "✅ 저장 성공: 그램피언스\n",
            "⏳ 분석 시작: 푸드실방 (리뷰 21개)\n",
            "✅ 저장 성공: 푸드실방\n",
            "⏳ 분석 시작: 피자빌스 (리뷰 33개)\n",
            "✅ 저장 성공: 피자빌스\n",
            "⏳ 분석 시작: 타이거보틀샵 (리뷰 2개)\n",
            "✅ 저장 성공: 타이거보틀샵\n",
            "⏳ 분석 시작: 스낵팩 멜번 망원 (리뷰 3개)\n",
            "✅ 저장 성공: 스낵팩 멜번 망원\n",
            "⏳ 분석 시작: 둥글 (리뷰 9개)\n",
            "✅ 저장 성공: 둥글\n",
            "⏳ 분석 시작: 델피스 스테이크버거 (리뷰 9개)\n",
            "✅ 저장 성공: 델피스 스테이크버거\n",
            "⏳ 분석 시작: 소셜다이닝 피델리오 (리뷰 2개)\n",
            "✅ 저장 성공: 소셜다이닝 피델리오\n",
            "⏳ 분석 시작: 프롬하노이 (리뷰 100개)\n",
            "✅ 저장 성공: 프롬하노이\n",
            "⏳ 분석 시작: 발리인망원 (리뷰 100개)\n",
            "✅ 저장 성공: 발리인망원\n",
            "⏳ 분석 시작: 포썸 (리뷰 72개)\n",
            "✅ 저장 성공: 포썸\n",
            "⏳ 분석 시작: 코랏 (리뷰 100개)\n",
            "✅ 저장 성공: 코랏\n",
            "⏳ 분석 시작: 엉클포 (리뷰 16개)\n",
            "✅ 저장 성공: 엉클포\n",
            "⏳ 분석 시작: 고타이 (리뷰 89개)\n",
            "✅ 저장 성공: 고타이\n",
            "⏳ 분석 시작: 하노이엔 (리뷰 57개)\n",
            "✅ 저장 성공: 하노이엔\n",
            "⏳ 분석 시작: 르보분 (리뷰 34개)\n",
            "✅ 저장 성공: 르보분\n",
            "⏳ 분석 시작: 포옹남망원 (리뷰 3개)\n",
            "✅ 저장 성공: 포옹남망원\n",
            "⏳ 분석 시작: 신짜오 (리뷰 8개)\n",
            "✅ 저장 성공: 신짜오\n",
            "⏳ 분석 시작: 밀객 (리뷰 19개)\n",
            "✅ 저장 성공: 밀객\n",
            "⏳ 분석 시작: 코브라파스타클럽 (리뷰 34개)\n",
            "✅ 저장 성공: 코브라파스타클럽\n",
            "⏳ 분석 시작: 땡초곱창 망원점 (리뷰 39개)\n",
            "✅ 저장 성공: 땡초곱창 망원점\n",
            "⏳ 분석 시작: 족발천하 망원점 (리뷰 18개)\n",
            "✅ 저장 성공: 족발천하 망원점\n",
            "⏳ 분석 시작: 고기도국수면 (리뷰 45개)\n",
            "✅ 저장 성공: 고기도국수면\n",
            "⏳ 분석 시작: 황제정육식당 망원점 (리뷰 14개)\n",
            "✅ 저장 성공: 황제정육식당 망원점\n",
            "⏳ 분석 시작: 돼지야 (리뷰 10개)\n",
            "✅ 저장 성공: 돼지야\n",
            "⏳ 분석 시작: 강통족발 (리뷰 10개)\n",
            "✅ 저장 성공: 강통족발\n",
            "⏳ 분석 시작: 삼겹살데이 (리뷰 17개)\n",
            "✅ 저장 성공: 삼겹살데이\n",
            "⏳ 분석 시작: 본가껍데기 본점 (리뷰 26개)\n",
            "✅ 저장 성공: 본가껍데기 본점\n",
            "⏳ 분석 시작: 지호한방삼계탕 마포구청역점 (리뷰 15개)\n",
            "✅ 저장 성공: 지호한방삼계탕 마포구청역점\n",
            "⏳ 분석 시작: 망원꽃돼지 (리뷰 16개)\n",
            "✅ 저장 성공: 망원꽃돼지\n",
            "⏳ 분석 시작: 망원숯불갈비 (리뷰 27개)\n",
            "✅ 저장 성공: 망원숯불갈비\n",
            "⏳ 분석 시작: 6호선닭한마리 (리뷰 28개)\n",
            "✅ 저장 성공: 6호선닭한마리\n",
            "⏳ 분석 시작: 연탄불소금구이 (리뷰 10개)\n",
            "✅ 저장 성공: 연탄불소금구이\n",
            "⏳ 분석 시작: 교동왕족발 (리뷰 9개)\n",
            "✅ 저장 성공: 교동왕족발\n",
            "⏳ 분석 시작: 육회by유신 망원점 (리뷰 11개)\n",
            "✅ 저장 성공: 육회by유신 망원점\n",
            "⏳ 분석 시작: 망원떡갈비 (리뷰 40개)\n",
            "✅ 저장 성공: 망원떡갈비\n",
            "⏳ 분석 시작: 삼삼이네삼겹살 (리뷰 5개)\n",
            "✅ 저장 성공: 삼삼이네삼겹살\n",
            "⏳ 분석 시작: 상암한우한마리 (리뷰 15개)\n",
            "✅ 저장 성공: 상암한우한마리\n",
            "⏳ 분석 시작: 장군이네 대패삼겹 (리뷰 2개)\n",
            "✅ 저장 성공: 장군이네 대패삼겹\n",
            "⏳ 분석 시작: 월강김치생삼겹살 (리뷰 39개)\n",
            "✅ 저장 성공: 월강김치생삼겹살\n",
            "⏳ 분석 시작: 엉터리생고기 무한대패 망원점 (리뷰 8개)\n",
            "✅ 저장 성공: 엉터리생고기 무한대패 망원점\n",
            "⏳ 분석 시작: 대패상회 (리뷰 15개)\n",
            "✅ 저장 성공: 대패상회\n",
            "⏳ 분석 시작: 망원 굽 (리뷰 9개)\n",
            "✅ 저장 성공: 망원 굽\n",
            "⏳ 분석 시작: 동래정 망원점 (리뷰 36개)\n",
            "✅ 저장 성공: 동래정 망원점\n",
            "⏳ 분석 시작: 자매네삼곱 (리뷰 16개)\n",
            "✅ 저장 성공: 자매네삼곱\n",
            "⏳ 분석 시작: 한강돼지집 (리뷰 17개)\n",
            "✅ 저장 성공: 한강돼지집\n",
            "⏳ 분석 시작: 고기로19 (리뷰 1개)\n",
            "✅ 저장 성공: 고기로19\n",
            "⏳ 분석 시작: 솥고집 마포구청역점 (리뷰 10개)\n",
            "✅ 저장 성공: 솥고집 마포구청역점\n",
            "⏳ 분석 시작: 만복기사식당 (리뷰 96개)\n",
            "✅ 저장 성공: 만복기사식당\n",
            "⏳ 분석 시작: 엄마손쌈밥집 (리뷰 12개)\n",
            "✅ 저장 성공: 엄마손쌈밥집\n",
            "⏳ 분석 시작: 지리산김치찌개 (리뷰 6개)\n",
            "✅ 저장 성공: 지리산김치찌개\n",
            "⏳ 분석 시작: 망원감자탕 (리뷰 3개)\n",
            "✅ 저장 성공: 망원감자탕\n",
            "⏳ 분석 시작: 만월 (리뷰 4개)\n",
            "✅ 저장 성공: 만월\n",
            "⏳ 분석 시작: 여장군 망원점 (리뷰 46개)\n",
            "✅ 저장 성공: 여장군 망원점\n",
            "⏳ 분석 시작: 우정식당 (리뷰 5개)\n",
            "✅ 저장 성공: 우정식당\n",
            "⏳ 분석 시작: 꽃삼정 본점 (리뷰 1개)\n",
            "✅ 저장 성공: 꽃삼정 본점\n",
            "⏳ 분석 시작: 훈이네빈대떡 (리뷰 7개)\n",
            "✅ 저장 성공: 훈이네빈대떡\n",
            "⏳ 분석 시작: 더드림 김치요리전문점 망원점 (리뷰 30개)\n",
            "✅ 저장 성공: 더드림 김치요리전문점 망원점\n",
            "⏳ 분석 시작: 전주식당 (리뷰 3개)\n",
            "✅ 저장 성공: 전주식당\n",
            "⏳ 분석 시작: 가정식고바우식당 (리뷰 20개)\n",
            "✅ 저장 성공: 가정식고바우식당\n",
            "⏳ 분석 시작: 마포나루 (리뷰 6개)\n",
            "✅ 저장 성공: 마포나루\n",
            "⏳ 분석 시작: 숯불설레임 (리뷰 15개)\n",
            "✅ 저장 성공: 숯불설레임\n",
            "⏳ 분석 시작: 신당동이모네곱창 (리뷰 7개)\n",
            "✅ 저장 성공: 신당동이모네곱창\n",
            "⏳ 분석 시작: 용머리 횟집 (리뷰 15개)\n",
            "✅ 저장 성공: 용머리 횟집\n",
            "⏳ 분석 시작: 현이네회시장 (리뷰 20개)\n",
            "✅ 저장 성공: 현이네회시장\n",
            "⏳ 분석 시작: 369 활어회포장전문 (리뷰 5개)\n",
            "✅ 저장 성공: 369 활어회포장전문\n",
            "⏳ 분석 시작: 아끼야 (리뷰 3개)\n",
            "✅ 저장 성공: 아끼야\n",
            "⏳ 분석 시작: 단바 서울 (리뷰 29개)\n",
            "✅ 저장 성공: 단바 서울\n",
            "⏳ 분석 시작: 후라이보이 망원점 (리뷰 5개)\n",
            "✅ 저장 성공: 후라이보이 망원점\n",
            "⏳ 분석 시작: 토리야타이 (리뷰 9개)\n",
            "✅ 저장 성공: 토리야타이\n",
            "⏳ 분석 시작: 안티소셜위스키클럽 (리뷰 14개)\n",
            "✅ 저장 성공: 안티소셜위스키클럽\n",
            "⏳ 분석 시작: 역전할머니맥주 망원점 (리뷰 20개)\n",
            "✅ 저장 성공: 역전할머니맥주 망원점\n",
            "⏳ 분석 시작: 홍대무라 (리뷰 17개)\n",
            "✅ 저장 성공: 홍대무라\n",
            "⏳ 분석 시작: 프로그 (리뷰 41개)\n",
            "✅ 저장 성공: 프로그\n",
            "⏳ 분석 시작: 즐거운포차 (리뷰 9개)\n",
            "✅ 저장 성공: 즐거운포차\n",
            "⏳ 분석 시작: 아부찌부대찌개 망원점 (리뷰 2개)\n",
            "✅ 저장 성공: 아부찌부대찌개 망원점\n",
            "⏳ 분석 시작: 타코야키쿤 (리뷰 39개)\n",
            "✅ 저장 성공: 타코야키쿤\n",
            "⏳ 분석 시작: 로바타우직 (리뷰 37개)\n",
            "✅ 저장 성공: 로바타우직\n",
            "⏳ 분석 시작: 코멘터리사운드 (리뷰 28개)\n",
            "✅ 저장 성공: 코멘터리사운드\n",
            "⏳ 분석 시작: 공작 (리뷰 21개)\n",
            "✅ 저장 성공: 공작\n",
            "⏳ 분석 시작: 마개 (리뷰 7개)\n",
            "✅ 저장 성공: 마개\n",
            "⏳ 분석 시작: 리파인 망원 (리뷰 22개)\n",
            "✅ 저장 성공: 리파인 망원\n",
            "⏳ 분석 시작: 라비뛰드 (리뷰 23개)\n",
            "✅ 저장 성공: 라비뛰드\n",
            "⏳ 분석 시작: 뱃놀이 (리뷰 34개)\n",
            "✅ 저장 성공: 뱃놀이\n",
            "⏳ 분석 시작: 포도당 (리뷰 10개)\n",
            "✅ 저장 성공: 포도당\n",
            "⏳ 분석 시작: 풀 발효부엌 (리뷰 57개)\n",
            "✅ 저장 성공: 풀 발효부엌\n",
            "⏳ 분석 시작: 매실(maesil) (리뷰 25개)\n",
            "✅ 저장 성공: 매실(maesil)\n",
            "⏳ 분석 시작: 성광대도 망원 (리뷰 4개)\n",
            "✅ 저장 성공: 성광대도 망원\n",
            "⏳ 분석 시작: 마초나초 (리뷰 9개)\n",
            "✅ 저장 성공: 마초나초\n",
            "⏳ 분석 시작: 싱싱샐러드 망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 싱싱샐러드 망원점\n",
            "⏳ 분석 시작: 시포 (리뷰 2개)\n",
            "✅ 저장 성공: 시포\n",
            "⏳ 분석 시작: 르디바인 망원 LeDevine mangwon (리뷰 14개)\n",
            "✅ 저장 성공: 르디바인 망원 LeDevine mangwon\n",
            "⏳ 분석 시작: 아루감 (리뷰 30개)\n",
            "✅ 저장 성공: 아루감\n",
            "⏳ 분석 시작: 하이에나 (리뷰 20개)\n",
            "✅ 저장 성공: 하이에나\n",
            "⏳ 분석 시작: 프레퍼스 망원직영점 (리뷰 1개)\n",
            "✅ 저장 성공: 프레퍼스 망원직영점\n",
            "⏳ 분석 시작: 카테고리나인 (리뷰 2개)\n",
            "✅ 저장 성공: 카테고리나인\n",
            "⏳ 분석 시작: 자마버거 (리뷰 6개)\n",
            "✅ 저장 성공: 자마버거\n",
            "⏳ 분석 시작: 맥도날드 망원점 (리뷰 44개)\n",
            "✅ 저장 성공: 맥도날드 망원점\n",
            "⏳ 분석 시작: 맘스터치 망원역점 (리뷰 38개)\n",
            "✅ 저장 성공: 맘스터치 망원역점\n",
            "⏳ 분석 시작: 버거킹 마포구청역점 (리뷰 30개)\n",
            "✅ 저장 성공: 버거킹 마포구청역점\n",
            "⏳ 분석 시작: 롯데리아 망원점 (리뷰 34개)\n",
            "✅ 저장 성공: 롯데리아 망원점\n",
            "⏳ 분석 시작: BBQ 망원점 (리뷰 25개)\n",
            "✅ 저장 성공: BBQ 망원점\n",
            "⏳ 분석 시작: 박군치킨 (리뷰 4개)\n",
            "✅ 저장 성공: 박군치킨\n",
            "⏳ 분석 시작: 숯불바베큐치킨 (리뷰 6개)\n",
            "✅ 저장 성공: 숯불바베큐치킨\n",
            "⏳ 분석 시작: 윤사부치킨 망원점 (리뷰 9개)\n",
            "✅ 저장 성공: 윤사부치킨 망원점\n",
            "⏳ 분석 시작: BHC치킨 망원점 (리뷰 16개)\n",
            "✅ 저장 성공: BHC치킨 망원점\n",
            "⏳ 분석 시작: 계림원 망원점 (리뷰 20개)\n",
            "✅ 저장 성공: 계림원 망원점\n",
            "⏳ 분석 시작: 큐큐치킨 (리뷰 15개)\n",
            "✅ 저장 성공: 큐큐치킨\n",
            "⏳ 분석 시작: 화락바베큐치킨 망원역점 (리뷰 3개)\n",
            "✅ 저장 성공: 화락바베큐치킨 망원역점\n",
            "⏳ 분석 시작: 광계토 숯불바베큐 (리뷰 21개)\n",
            "✅ 저장 성공: 광계토 숯불바베큐\n",
            "⏳ 분석 시작: 후라이드참잘하는집 마포점 (리뷰 7개)\n",
            "✅ 저장 성공: 후라이드참잘하는집 마포점\n",
            "⏳ 분석 시작: 동근이숯불두마리치킨 서울망원점 (리뷰 16개)\n",
            "✅ 저장 성공: 동근이숯불두마리치킨 서울망원점\n",
            "⏳ 분석 시작: 티바두마리치킨 망원점 (리뷰 5개)\n",
            "✅ 저장 성공: 티바두마리치킨 망원점\n",
            "⏳ 분석 시작: 반했닭옛날통닭 망원점 (리뷰 16개)\n",
            "✅ 저장 성공: 반했닭옛날통닭 망원점\n",
            "⏳ 분석 시작: 교촌치킨 망원2동점 (리뷰 34개)\n",
            "✅ 저장 성공: 교촌치킨 망원2동점\n",
            "⏳ 분석 시작: 페리카나 망원동점 (리뷰 5개)\n",
            "✅ 저장 성공: 페리카나 망원동점\n",
            "⏳ 분석 시작: 60계치킨 서울망원점 (리뷰 16개)\n",
            "✅ 저장 성공: 60계치킨 서울망원점\n",
            "⏳ 분석 시작: 가마치통닭 서울망원역점 (리뷰 9개)\n",
            "✅ 저장 성공: 가마치통닭 서울망원역점\n",
            "⏳ 분석 시작: 굽네치킨 망원1동점 (리뷰 13개)\n",
            "✅ 저장 성공: 굽네치킨 망원1동점\n",
            "⏳ 분석 시작: 또바기치킨 망원시장점 (리뷰 11개)\n",
            "✅ 저장 성공: 또바기치킨 망원시장점\n",
            "⏳ 분석 시작: 또래오래 마포망원점 (리뷰 5개)\n",
            "✅ 저장 성공: 또래오래 마포망원점\n",
            "⏳ 분석 시작: 탐스바베큐 TOM'S B.B.Q (리뷰 3개)\n",
            "✅ 저장 성공: 탐스바베큐 TOM'S B.B.Q\n",
            "⏳ 분석 시작: 썬더치킨 망원점 (리뷰 3개)\n",
            "✅ 저장 성공: 썬더치킨 망원점\n",
            "⏳ 분석 시작: 푸라닭치킨 망원점 (리뷰 6개)\n",
            "✅ 저장 성공: 푸라닭치킨 망원점\n",
            "⏳ 분석 시작: 네네치킨 망원점 (리뷰 10개)\n",
            "✅ 저장 성공: 네네치킨 망원점\n",
            "⏳ 분석 시작: 정드린치킨 망원점 (리뷰 7개)\n",
            "✅ 저장 성공: 정드린치킨 망원점\n",
            "⏳ 분석 시작: 바베큐치킨 참잘하는집 (리뷰 1개)\n",
            "✅ 저장 성공: 바베큐치킨 참잘하는집\n",
            "⏳ 분석 시작: 도월리가 (리뷰 27개)\n",
            "✅ 저장 성공: 도월리가\n",
            "⏳ 분석 시작: 친친국밥 (리뷰 21개)\n",
            "✅ 저장 성공: 친친국밥\n",
            "⏳ 분석 시작: 묘내 (리뷰 3개)\n",
            "✅ 저장 성공: 묘내\n",
            "⏳ 분석 시작: 전주가콩나물국밥전문점 망원역점 (리뷰 35개)\n",
            "✅ 저장 성공: 전주가콩나물국밥전문점 망원역점\n",
            "⏳ 분석 시작: 한우소머리국밥 (리뷰 7개)\n",
            "✅ 저장 성공: 한우소머리국밥\n",
            "⏳ 분석 시작: 망원부자부대찌개 (리뷰 17개)\n",
            "✅ 저장 성공: 망원부자부대찌개\n",
            "⏳ 분석 시작: 망원란이김치찌개 (리뷰 10개)\n",
            "✅ 저장 성공: 망원란이김치찌개\n",
            "⏳ 분석 시작: 땅스부대찌개 망원월드컵시장점 (리뷰 7개)\n",
            "✅ 저장 성공: 땅스부대찌개 망원월드컵시장점\n",
            "⏳ 분석 시작: 고향집칼국수 (리뷰 1개)\n",
            "✅ 저장 성공: 고향집칼국수\n",
            "⏳ 분석 시작: 씨스터버섯매운칼국수 (리뷰 49개)\n",
            "✅ 저장 성공: 씨스터버섯매운칼국수\n",
            "⏳ 분석 시작: 밀면집 (리뷰 61개)\n",
            "✅ 저장 성공: 밀면집\n",
            "⏳ 분석 시작: 임가네해물천국 (리뷰 9개)\n",
            "✅ 저장 성공: 임가네해물천국\n",
            "⏳ 분석 시작: 도화식당 (리뷰 9개)\n",
            "✅ 저장 성공: 도화식당\n",
            "⏳ 분석 시작: 꼬치주간 (리뷰 67개)\n",
            "✅ 저장 성공: 꼬치주간\n",
            "⏳ 분석 시작: 스트렁큰 (리뷰 1개)\n",
            "✅ 저장 성공: 스트렁큰\n",
            "⏳ 분석 시작: 장모님멸치국수 (리뷰 47개)\n",
            "✅ 저장 성공: 장모님멸치국수\n",
            "⏳ 분석 시작: 오봉집 망원점 (리뷰 24개)\n",
            "✅ 저장 성공: 오봉집 망원점\n",
            "⏳ 분석 시작: 한창희천하일면 망원점 (리뷰 9개)\n",
            "✅ 저장 성공: 한창희천하일면 망원점\n",
            "⏳ 분석 시작: 망원동 막국수 (리뷰 28개)\n",
            "✅ 저장 성공: 망원동 막국수\n",
            "⏳ 분석 시작: 모가정국수 (리뷰 7개)\n",
            "✅ 저장 성공: 모가정국수\n",
            "⏳ 분석 시작: 알짜배기 (리뷰 3개)\n",
            "✅ 저장 성공: 알짜배기\n",
            "⏳ 분석 시작: 무침프로젝트 홍어무침 망원점 (리뷰 22개)\n",
            "✅ 저장 성공: 무침프로젝트 홍어무침 망원점\n",
            "⏳ 분석 시작: 위군 (리뷰 21개)\n",
            "✅ 저장 성공: 위군\n",
            "⏳ 분석 시작: 섬 본점 (리뷰 22개)\n",
            "✅ 저장 성공: 섬 본점\n",
            "⏳ 분석 시작: 나나 (리뷰 34개)\n",
            "✅ 저장 성공: 나나\n",
            "⏳ 분석 시작: 낯꽃 (리뷰 4개)\n",
            "✅ 저장 성공: 낯꽃\n",
            "⏳ 분석 시작: 온리 (리뷰 4개)\n",
            "✅ 저장 성공: 온리\n",
            "⏳ 분석 시작: 계춘몽 (리뷰 6개)\n",
            "✅ 저장 성공: 계춘몽\n",
            "⏳ 분석 시작: 닭도리탕한마리 (리뷰 13개)\n",
            "✅ 저장 성공: 닭도리탕한마리\n",
            "⏳ 분석 시작: 원할머니보쌈족발 망원점 (리뷰 0개)\n",
            "✅ 저장 성공: 원할머니보쌈족발 망원점\n",
            "⏳ 분석 시작: 장수한방족발 (리뷰 5개)\n",
            "✅ 저장 성공: 장수한방족발\n",
            "⏳ 분석 시작: 장충동한방족발 (리뷰 1개)\n",
            "✅ 저장 성공: 장충동한방족발\n",
            "⏳ 분석 시작: 명성족발 (리뷰 13개)\n",
            "✅ 저장 성공: 명성족발\n",
            "⏳ 분석 시작: 고려왕족발 (리뷰 11개)\n",
            "✅ 저장 성공: 고려왕족발\n",
            "⏳ 분석 시작: 우이락 망원본점 (리뷰 100개)\n",
            "✅ 저장 성공: 우이락 망원본점\n",
            "⏳ 분석 시작: 한촌설렁탕 망원역점 (리뷰 20개)\n",
            "✅ 저장 성공: 한촌설렁탕 망원역점\n",
            "⏳ 분석 시작: 황금옥순대전문 (리뷰 44개)\n",
            "✅ 저장 성공: 황금옥순대전문\n",
            "⏳ 분석 시작: 양평해장국 (리뷰 16개)\n",
            "✅ 저장 성공: 양평해장국\n",
            "⏳ 분석 시작: 상암순대국 (리뷰 28개)\n",
            "✅ 저장 성공: 상암순대국\n",
            "⏳ 분석 시작: 달고나 (리뷰 55개)\n",
            "✅ 저장 성공: 달고나\n",
            "⏳ 분석 시작: 신의주순대와쭈꾸미 망원점 (리뷰 15개)\n",
            "✅ 저장 성공: 신의주순대와쭈꾸미 망원점\n",
            "⏳ 분석 시작: 레이크 망원 (리뷰 13개)\n",
            "✅ 저장 성공: 레이크 망원\n",
            "⏳ 분석 시작: 부엉이산장 망원점 (리뷰 13개)\n",
            "✅ 저장 성공: 부엉이산장 망원점\n",
            "⏳ 분석 시작: 마장동우뚝 (리뷰 32개)\n",
            "✅ 저장 성공: 마장동우뚝\n",
            "⏳ 분석 시작: 신의주찹쌀순대 (리뷰 2개)\n",
            "✅ 저장 성공: 신의주찹쌀순대\n",
            "⏳ 분석 시작: 신현만의한우곰탕 육회비빔밥 (리뷰 2개)\n",
            "✅ 저장 성공: 신현만의한우곰탕 육회비빔밥\n",
            "⏳ 분석 시작: 뜻뜻 (리뷰 8개)\n",
            "✅ 저장 성공: 뜻뜻\n",
            "⏳ 분석 시작: 너랑나랑호프 망원점 (리뷰 76개)\n",
            "✅ 저장 성공: 너랑나랑호프 망원점\n",
            "⏳ 분석 시작: 일번지대박집 (리뷰 11개)\n",
            "✅ 저장 성공: 일번지대박집\n",
            "⏳ 분석 시작: 노가리와호프 (리뷰 9개)\n",
            "✅ 저장 성공: 노가리와호프\n",
            "⏳ 분석 시작: 만나포차 (리뷰 3개)\n",
            "✅ 저장 성공: 만나포차\n",
            "⏳ 분석 시작: 투다리 망원2점 (리뷰 3개)\n",
            "✅ 저장 성공: 투다리 망원2점\n",
            "⏳ 분석 시작: 치꼬뱅 (리뷰 0개)\n",
            "✅ 저장 성공: 치꼬뱅\n",
            "⏳ 분석 시작: 투다리 망원한강공원점 (리뷰 6개)\n",
            "✅ 저장 성공: 투다리 망원한강공원점\n",
            "⏳ 분석 시작: 한강가자 (리뷰 8개)\n",
            "✅ 저장 성공: 한강가자\n",
            "⏳ 분석 시작: 깡포차 (리뷰 3개)\n",
            "✅ 저장 성공: 깡포차\n",
            "⏳ 분석 시작: 행복나들맛집 (리뷰 3개)\n",
            "✅ 저장 성공: 행복나들맛집\n",
            "⏳ 분석 시작: 한강포차 (리뷰 1개)\n",
            "✅ 저장 성공: 한강포차\n",
            "⏳ 분석 시작: 왕뼈감자탕 망원직영점 (리뷰 13개)\n",
            "✅ 저장 성공: 왕뼈감자탕 망원직영점\n",
            "⏳ 분석 시작: 용머리감자탕 (리뷰 11개)\n",
            "✅ 저장 성공: 용머리감자탕\n",
            "⏳ 분석 시작: 정국밥 (리뷰 9개)\n",
            "✅ 저장 성공: 정국밥\n",
            "⏳ 분석 시작: 소담 (리뷰 2개)\n",
            "✅ 저장 성공: 소담\n",
            "⏳ 분석 시작: 예원이네 (리뷰 2개)\n",
            "✅ 저장 성공: 예원이네\n",
            "⏳ 분석 시작: 망원식당 (리뷰 40개)\n",
            "✅ 저장 성공: 망원식당\n",
            "⏳ 분석 시작: 구내식당 (리뷰 17개)\n",
            "✅ 저장 성공: 구내식당\n",
            "⏳ 분석 시작: 주로 (리뷰 3개)\n",
            "✅ 저장 성공: 주로\n",
            "⏳ 분석 시작: 옌징바 (리뷰 29개)\n",
            "✅ 저장 성공: 옌징바\n",
            "⏳ 분석 시작: 망원샌드 (리뷰 2개)\n",
            "✅ 저장 성공: 망원샌드\n",
            "⏳ 분석 시작: 샐러드하임 (리뷰 35개)\n",
            "✅ 저장 성공: 샐러드하임\n",
            "⏳ 분석 시작: 그린앤피니 망원본점 (리뷰 5개)\n",
            "✅ 저장 성공: 그린앤피니 망원본점\n",
            "⏳ 분석 시작: 소금집델리 망원 (리뷰 100개)\n",
            "✅ 저장 성공: 소금집델리 망원\n",
            "⏳ 분석 시작: 리앙키친 본점 (리뷰 3개)\n",
            "✅ 저장 성공: 리앙키친 본점\n",
            "⏳ 분석 시작: 망원수제고로케 (리뷰 83개)\n",
            "✅ 저장 성공: 망원수제고로케\n",
            "⏳ 분석 시작: 구운 (리뷰 49개)\n",
            "✅ 저장 성공: 구운\n",
            "⏳ 분석 시작: 호아 (리뷰 11개)\n",
            "✅ 저장 성공: 호아\n",
            "⏳ 분석 시작: 일랑비어하우스 (리뷰 18개)\n",
            "✅ 저장 성공: 일랑비어하우스\n",
            "⏳ 분석 시작: 파리바게뜨 망원점 (리뷰 15개)\n",
            "✅ 저장 성공: 파리바게뜨 망원점\n",
            "⏳ 분석 시작: 웅장 (리뷰 21개)\n",
            "✅ 저장 성공: 웅장\n",
            "⏳ 분석 시작: 화월 (리뷰 12개)\n",
            "✅ 저장 성공: 화월\n",
            "⏳ 분석 시작: 진다이브 (리뷰 6개)\n",
            "✅ 저장 성공: 진다이브\n",
            "⏳ 분석 시작: 파리바게뜨 망원역점 (리뷰 8개)\n",
            "✅ 저장 성공: 파리바게뜨 망원역점\n",
            "⏳ 분석 시작: 본죽&비빔밥cafe 망원역점 (리뷰 25개)\n",
            "✅ 저장 성공: 본죽&비빔밥cafe 망원역점\n",
            "⏳ 분석 시작: 망원양화 (리뷰 4개)\n",
            "✅ 저장 성공: 망원양화\n",
            "⏳ 분석 시작: 진토리닭곰탕 (리뷰 9개)\n",
            "✅ 저장 성공: 진토리닭곰탕\n",
            "⏳ 분석 시작: 한옥집김치찜 (리뷰 6개)\n",
            "✅ 저장 성공: 한옥집김치찜\n",
            "⏳ 분석 시작: 이천억 해물이랑고기랑 직영본점 (리뷰 2개)\n",
            "✅ 저장 성공: 이천억 해물이랑고기랑 직영본점\n",
            "⏳ 분석 시작: 고향전 (리뷰 8개)\n",
            "✅ 저장 성공: 고향전\n",
            "⏳ 분석 시작: 인정쭈꾸미 망원점 (리뷰 26개)\n",
            "✅ 저장 성공: 인정쭈꾸미 망원점\n",
            "⏳ 분석 시작: 제육대가 쭈대가 마포구청점 (리뷰 3개)\n",
            "✅ 저장 성공: 제육대가 쭈대가 마포구청점\n",
            "⏳ 분석 시작: 로뎀식당 (리뷰 7개)\n",
            "✅ 저장 성공: 로뎀식당\n",
            "⏳ 분석 시작: 텐덜리 (리뷰 10개)\n",
            "✅ 저장 성공: 텐덜리\n",
            "⏳ 분석 시작: 부산본가 (리뷰 9개)\n",
            "✅ 저장 성공: 부산본가\n",
            "⏳ 분석 시작: 철길부산집 망원점 (리뷰 85개)\n",
            "✅ 저장 성공: 철길부산집 망원점\n",
            "⏳ 분석 시작: 대산집 (리뷰 7개)\n",
            "✅ 저장 성공: 대산집\n",
            "⏳ 분석 시작: 명성한우 (리뷰 3개)\n",
            "✅ 저장 성공: 명성한우\n",
            "⏳ 분석 시작: 마더죽카페 (리뷰 2개)\n",
            "✅ 저장 성공: 마더죽카페\n",
            "⏳ 분석 시작: 썬릿25 (리뷰 8개)\n",
            "✅ 저장 성공: 썬릿25\n",
            "⏳ 분석 시작: 전통맛죽 (리뷰 2개)\n",
            "✅ 저장 성공: 전통맛죽\n",
            "⏳ 분석 시작: 본가마산아구찜 (리뷰 12개)\n",
            "✅ 저장 성공: 본가마산아구찜\n",
            "⏳ 분석 시작: 참맛닭곰탕 (리뷰 5개)\n",
            "✅ 저장 성공: 참맛닭곰탕\n",
            "⏳ 분석 시작: 열정타코 망원점 (리뷰 63개)\n",
            "✅ 저장 성공: 열정타코 망원점\n",
            "⏳ 분석 시작: 히츠지야 망리단길점 (리뷰 28개)\n",
            "✅ 저장 성공: 히츠지야 망리단길점\n",
            "⏳ 분석 시작: 오코노미야키골드 (리뷰 17개)\n",
            "✅ 저장 성공: 오코노미야키골드\n",
            "⏳ 분석 시작: 깡치네 망원본점 (리뷰 16개)\n",
            "✅ 저장 성공: 깡치네 망원본점\n",
            "⏳ 분석 시작: 유포장마차 (리뷰 1개)\n",
            "✅ 저장 성공: 유포장마차\n",
            "⏳ 분석 시작: 초반식당 망원점 (리뷰 12개)\n",
            "✅ 저장 성공: 초반식당 망원점\n",
            "⏳ 분석 시작: 반주 (리뷰 15개)\n",
            "✅ 저장 성공: 반주\n",
            "⏳ 분석 시작: 쌈싸먹는민족 본점 (리뷰 21개)\n",
            "✅ 저장 성공: 쌈싸먹는민족 본점\n",
            "⏳ 분석 시작: 진부령황태촌 망원점 (리뷰 20개)\n",
            "✅ 저장 성공: 진부령황태촌 망원점\n",
            "⏳ 분석 시작: 나들목빈대떡 (리뷰 29개)\n",
            "✅ 저장 성공: 나들목빈대떡\n",
            "⏳ 분석 시작: 금붕어식당 (리뷰 3개)\n",
            "✅ 저장 성공: 금붕어식당\n",
            "⏳ 분석 시작: 도스 (리뷰 4개)\n",
            "✅ 저장 성공: 도스\n",
            "⏳ 분석 시작: 토터 (리뷰 5개)\n",
            "✅ 저장 성공: 토터\n",
            "⏳ 분석 시작: 이구역의요리왕 (리뷰 6개)\n",
            "✅ 저장 성공: 이구역의요리왕\n",
            "⏳ 분석 시작: 저집 망원점 (리뷰 11개)\n",
            "✅ 저장 성공: 저집 망원점\n",
            "⏳ 분석 시작: 말쑥이전포차 (리뷰 1개)\n",
            "✅ 저장 성공: 말쑥이전포차\n",
            "⏳ 분석 시작: 아리조나불백 (리뷰 2개)\n",
            "✅ 저장 성공: 아리조나불백\n",
            "⏳ 분석 시작: 바코드포차 (리뷰 1개)\n",
            "✅ 저장 성공: 바코드포차\n",
            "⏳ 분석 시작: 반갑소갈비탕 (리뷰 2개)\n",
            "✅ 저장 성공: 반갑소갈비탕\n",
            "⏳ 분석 시작: 명가낙지마당 망원점 (리뷰 11개)\n",
            "✅ 저장 성공: 명가낙지마당 망원점\n",
            "⏳ 분석 시작: 망원틈새전 (리뷰 5개)\n",
            "✅ 저장 성공: 망원틈새전\n",
            "⏳ 분석 시작: 홍뎅 (리뷰 9개)\n",
            "✅ 저장 성공: 홍뎅\n",
            "⏳ 분석 시작: 쿠로 (리뷰 44개)\n",
            "✅ 저장 성공: 쿠로\n",
            "⏳ 분석 시작: 리틀스탠드레몽 (리뷰 24개)\n",
            "✅ 저장 성공: 리틀스탠드레몽\n",
            "⏳ 분석 시작: 망원동 나경이네 (리뷰 6개)\n",
            "✅ 저장 성공: 망원동 나경이네\n",
            "⏳ 분석 시작: GRANWAVE 그랑웨이브 (리뷰 9개)\n",
            "✅ 저장 성공: GRANWAVE 그랑웨이브\n",
            "⏳ 분석 시작: 유유 (리뷰 3개)\n",
            "✅ 저장 성공: 유유\n",
            "⏳ 분석 시작: 살쾡이 (리뷰 25개)\n",
            "✅ 저장 성공: 살쾡이\n",
            "⏳ 분석 시작: 아카사카참치전문점 (리뷰 6개)\n",
            "✅ 저장 성공: 아카사카참치전문점\n",
            "⏳ 분석 시작: 써브웨이 망원역점 (리뷰 70개)\n",
            "✅ 저장 성공: 써브웨이 망원역점\n",
            "⏳ 분석 시작: 써브웨이 망원한강공원점 (리뷰 19개)\n",
            "✅ 저장 성공: 써브웨이 망원한강공원점\n",
            "⏳ 분석 시작: 소코아 망원점 (리뷰 1개)\n",
            "✅ 저장 성공: 소코아 망원점\n",
            "⏳ 분석 시작: 망원도 (리뷰 12개)\n",
            "✅ 저장 성공: 망원도\n",
            "⏳ 분석 시작: 원당가마솥찰옥수수 (리뷰 11개)\n",
            "✅ 저장 성공: 원당가마솥찰옥수수\n",
            "⏳ 분석 시작: 블렌딩바 망원 (리뷰 29개)\n",
            "✅ 저장 성공: 블렌딩바 망원\n",
            "⏳ 분석 시작: 이삭토스트 서울망원시장점 (리뷰 10개)\n",
            "✅ 저장 성공: 이삭토스트 서울망원시장점\n",
            "⏳ 분석 시작: 건어물라운지 (리뷰 6개)\n",
            "✅ 저장 성공: 건어물라운지\n",
            "⏳ 분석 시작: 소문난빈대떡마을 (리뷰 18개)\n",
            "✅ 저장 성공: 소문난빈대떡마을\n",
            "⏳ 분석 시작: 투스 (리뷰 4개)\n",
            "✅ 저장 성공: 투스\n",
            "⏳ 분석 시작: 한입 타코야끼 (리뷰 16개)\n",
            "✅ 저장 성공: 한입 타코야끼\n",
            "⏳ 분석 시작: 망원닭강정 (리뷰 40개)\n",
            "✅ 저장 성공: 망원닭강정\n",
            "⏳ 분석 시작: 가마로강정 망원점 (리뷰 22개)\n",
            "✅ 저장 성공: 가마로강정 망원점\n",
            "⏳ 분석 시작: 훈훈호떡 (리뷰 100개)\n",
            "✅ 저장 성공: 훈훈호떡\n",
            "⏳ 분석 시작: 원당수제고로케 (리뷰 12개)\n",
            "✅ 저장 성공: 원당수제고로케\n",
            "⏳ 분석 시작: 압구정고깃집 (리뷰 5개)\n",
            "✅ 저장 성공: 압구정고깃집\n",
            "⏳ 분석 시작: 생맥줏집 (리뷰 1개)\n",
            "✅ 저장 성공: 생맥줏집\n",
            "⏳ 분석 시작: 어글리베이커리 (리뷰 100개)\n",
            "✅ 저장 성공: 어글리베이커리\n",
            "⏳ 분석 시작: 후와후와 (리뷰 100개)\n",
            "✅ 저장 성공: 후와후와\n",
            "⏳ 분석 시작: 투떰즈업 (리뷰 100개)\n",
            "✅ 저장 성공: 투떰즈업\n",
            "⏳ 분석 시작: 브릭베이글 (리뷰 80개)\n",
            "✅ 저장 성공: 브릭베이글\n",
            "⏳ 분석 시작: 블랑제리코팡 (리뷰 100개)\n",
            "✅ 저장 성공: 블랑제리코팡\n",
            "⏳ 분석 시작: 스콘포드로그 (리뷰 51개)\n",
            "✅ 저장 성공: 스콘포드로그\n",
            "⏳ 분석 시작: 코토베이커리 (리뷰 10개)\n",
            "✅ 저장 성공: 코토베이커리\n",
            "⏳ 분석 시작: 후와후와 모치점 (리뷰 6개)\n",
            "✅ 저장 성공: 후와후와 모치점\n",
            "⏳ 분석 시작: 버터베이커리 망원 (리뷰 35개)\n",
            "✅ 저장 성공: 버터베이커리 망원\n",
            "⏳ 분석 시작: 구미가당 (리뷰 89개)\n",
            "✅ 저장 성공: 구미가당\n",
            "⏳ 분석 시작: 웅파이 미트파이 (리뷰 100개)\n",
            "✅ 저장 성공: 웅파이 미트파이\n",
            "⏳ 분석 시작: 밀로밀 (리뷰 100개)\n",
            "✅ 저장 성공: 밀로밀\n",
            "⏳ 분석 시작: 비번 (리뷰 15개)\n",
            "✅ 저장 성공: 비번\n",
            "⏳ 분석 시작: 라므아르 (리뷰 21개)\n",
            "✅ 저장 성공: 라므아르\n",
            "⏳ 분석 시작: 시우 (리뷰 49개)\n",
            "✅ 저장 성공: 시우\n",
            "⏳ 분석 시작: 졸리파이마켓 (리뷰 27개)\n",
            "✅ 저장 성공: 졸리파이마켓\n",
            "⏳ 분석 시작: 소소베이크하우스 (리뷰 32개)\n",
            "✅ 저장 성공: 소소베이크하우스\n",
            "⏳ 분석 시작: 하이놀리 (리뷰 54개)\n",
            "✅ 저장 성공: 하이놀리\n",
            "⏳ 분석 시작: 본연 (리뷰 6개)\n",
            "✅ 저장 성공: 본연\n",
            "⏳ 분석 시작: 라바즈 (리뷰 62개)\n",
            "✅ 저장 성공: 라바즈\n",
            "⏳ 분석 시작: 키토빵앗간 (리뷰 30개)\n",
            "✅ 저장 성공: 키토빵앗간\n",
            "⏳ 분석 시작: 흐쎄트 망원 (리뷰 6개)\n",
            "✅ 저장 성공: 흐쎄트 망원\n",
            "⏳ 분석 시작: 카스테라연구소 (리뷰 51개)\n",
            "✅ 저장 성공: 카스테라연구소\n",
            "⏳ 분석 시작: 베이크앤쏘 (리뷰 15개)\n",
            "✅ 저장 성공: 베이크앤쏘\n",
            "⏳ 분석 시작: 뚜레쥬르 마포구청역점 (리뷰 23개)\n",
            "✅ 저장 성공: 뚜레쥬르 마포구청역점\n",
            "⏳ 분석 시작: 비고미 (리뷰 53개)\n",
            "✅ 저장 성공: 비고미\n",
            "⏳ 분석 시작: 뇽뇽마카롱 (리뷰 9개)\n",
            "✅ 저장 성공: 뇽뇽마카롱\n",
            "⏳ 분석 시작: 클로버베이커리 (리뷰 18개)\n",
            "✅ 저장 성공: 클로버베이커리\n",
            "⏳ 분석 시작: 위켄드케이크 (리뷰 25개)\n",
            "✅ 저장 성공: 위켄드케이크\n",
            "⏳ 분석 시작: 크림데이 (리뷰 49개)\n",
            "✅ 저장 성공: 크림데이\n",
            "⏳ 분석 시작: 하나팡 (리뷰 6개)\n",
            "✅ 저장 성공: 하나팡\n",
            "⏳ 분석 시작: 천원의행복빵 망원시장점 (리뷰 1개)\n",
            "✅ 저장 성공: 천원의행복빵 망원시장점\n",
            "⏳ 분석 시작: 그래,좋아 (리뷰 2개)\n",
            "✅ 저장 성공: 그래,좋아\n",
            "⏳ 분석 시작: 감정선프로젝트 베이킹 망원점 (리뷰 56개)\n",
            "✅ 저장 성공: 감정선프로젝트 베이킹 망원점\n",
            "⏳ 분석 시작: 종관과자점 망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 종관과자점 망원점\n",
            "⏳ 분석 시작: 술빵술찐빵 (리뷰 2개)\n",
            "✅ 저장 성공: 술빵술찐빵\n",
            "⏳ 분석 시작: 당도 (리뷰 100개)\n",
            "✅ 저장 성공: 당도\n",
            "⏳ 분석 시작: 페이버 (리뷰 53개)\n",
            "✅ 저장 성공: 페이버\n",
            "⏳ 분석 시작: 돌체디앤 (리뷰 3개)\n",
            "✅ 저장 성공: 돌체디앤\n",
            "⏳ 분석 시작: 쁘띠보뇌르 망원본점 (리뷰 19개)\n",
            "✅ 저장 성공: 쁘띠보뇌르 망원본점\n",
            "⏳ 분석 시작: 블랑끼따 (리뷰 6개)\n",
            "✅ 저장 성공: 블랑끼따\n",
            "⏳ 분석 시작: 라베리타 (리뷰 2개)\n",
            "✅ 저장 성공: 라베리타\n",
            "⏳ 분석 시작: 비건앳홈 (리뷰 1개)\n",
            "✅ 저장 성공: 비건앳홈\n",
            "⏳ 분석 시작: 베잇킹 (리뷰 2개)\n",
            "✅ 저장 성공: 베잇킹\n",
            "⏳ 분석 시작: 그랜드나나파파 (리뷰 1개)\n",
            "✅ 저장 성공: 그랜드나나파파\n",
            "⏳ 분석 시작: 근제베이커리 (리뷰 6개)\n",
            "✅ 저장 성공: 근제베이커리\n",
            "⏳ 분석 시작: 하루가달고나 (리뷰 3개)\n",
            "✅ 저장 성공: 하루가달고나\n",
            "⏳ 분석 시작: 카카오다다 (리뷰 43개)\n",
            "✅ 저장 성공: 카카오다다\n",
            "⏳ 분석 시작: 잼인브레드 (리뷰 6개)\n",
            "✅ 저장 성공: 잼인브레드\n",
            "⏳ 분석 시작: 나이트앤데이 (리뷰 26개)\n",
            "✅ 저장 성공: 나이트앤데이\n",
            "⏳ 분석 시작: 미미당 (리뷰 4개)\n",
            "✅ 저장 성공: 미미당\n",
            "⏳ 분석 시작: 호랑이라운지 (리뷰 8개)\n",
            "✅ 저장 성공: 호랑이라운지\n",
            "⏳ 분석 시작: 비어트립 (리뷰 8개)\n",
            "✅ 저장 성공: 비어트립\n",
            "⏳ 분석 시작: 이오오 (리뷰 6개)\n",
            "✅ 저장 성공: 이오오\n",
            "⏳ 분석 시작: 디디앤숲 (리뷰 2개)\n",
            "✅ 저장 성공: 디디앤숲\n",
            "⏳ 분석 시작: 로메인키친 (리뷰 28개)\n",
            "✅ 저장 성공: 로메인키친\n",
            "⏳ 분석 시작: 120겹PIE (리뷰 1개)\n",
            "✅ 저장 성공: 120겹PIE\n",
            "⏳ 분석 시작: 단칸빵 (리뷰 9개)\n",
            "✅ 저장 성공: 단칸빵\n",
            "⏳ 분석 시작: 크렘크렘 (리뷰 11개)\n",
            "✅ 저장 성공: 크렘크렘\n",
            "⏳ 분석 시작: 망원튀맥집 (리뷰 22개)\n",
            "✅ 저장 성공: 망원튀맥집\n",
            "⏳ 분석 시작: 알코브 (리뷰 4개)\n",
            "✅ 저장 성공: 알코브\n",
            "⏳ 분석 시작: 공일토스트 (리뷰 1개)\n",
            "✅ 저장 성공: 공일토스트\n",
            "⏳ 분석 시작: 말라카이트 망원 (리뷰 15개)\n",
            "✅ 저장 성공: 말라카이트 망원\n",
            "⏳ 분석 시작: 솔나무떡집 (리뷰 16개)\n",
            "✅ 저장 성공: 솔나무떡집\n",
            "⏳ 분석 시작: 배스킨라빈스 망원역점 (리뷰 31개)\n",
            "✅ 저장 성공: 배스킨라빈스 망원역점\n",
            "⏳ 분석 시작: 포도앤몰트 (리뷰 1개)\n",
            "✅ 저장 성공: 포도앤몰트\n",
            "⏳ 분석 시작: 별하담 (리뷰 1개)\n",
            "✅ 저장 성공: 별하담\n",
            "⏳ 분석 시작: 아마 (리뷰 25개)\n",
            "✅ 저장 성공: 아마\n",
            "⏳ 분석 시작: 무주택 (리뷰 23개)\n",
            "✅ 저장 성공: 무주택\n",
            "⏳ 분석 시작: 책바 (리뷰 54개)\n",
            "✅ 저장 성공: 책바\n",
            "⏳ 분석 시작: 빌라마리아나 (리뷰 10개)\n",
            "✅ 저장 성공: 빌라마리아나\n",
            "⏳ 분석 시작: 바 사뭇 (리뷰 19개)\n",
            "✅ 저장 성공: 바 사뭇\n",
            "⏳ 분석 시작: 내잔 서울혼술바 망원점 (리뷰 6개)\n",
            "✅ 저장 성공: 내잔 서울혼술바 망원점\n",
            "⏳ 분석 시작: 초쿤바 (리뷰 41개)\n",
            "✅ 저장 성공: 초쿤바\n",
            "⏳ 분석 시작: 꿩먹고알먹고호프 (리뷰 100개)\n",
            "✅ 저장 성공: 꿩먹고알먹고호프\n",
            "⏳ 분석 시작: 휴식당 (리뷰 9개)\n",
            "✅ 저장 성공: 휴식당\n",
            "⏳ 분석 시작: 트릴로지 (리뷰 29개)\n",
            "✅ 저장 성공: 트릴로지\n",
            "⏳ 분석 시작: 능소화 (리뷰 4개)\n",
            "✅ 저장 성공: 능소화\n",
            "⏳ 분석 시작: 101호 (리뷰 2개)\n",
            "✅ 저장 성공: 101호\n",
            "⏳ 분석 시작: 살롱드낭만 (리뷰 17개)\n",
            "✅ 저장 성공: 살롱드낭만\n",
            "⏳ 분석 시작: 계월 (리뷰 6개)\n",
            "✅ 저장 성공: 계월\n",
            "⏳ 분석 시작: 시장맥주 (리뷰 25개)\n",
            "✅ 저장 성공: 시장맥주\n",
            "⏳ 분석 시작: 유진 (리뷰 8개)\n",
            "✅ 저장 성공: 유진\n",
            "⏳ 분석 시작: 망원양조 (리뷰 2개)\n",
            "✅ 저장 성공: 망원양조\n",
            "⏳ 분석 시작: 전조 (리뷰 5개)\n",
            "✅ 저장 성공: 전조\n",
            "⏳ 분석 시작: 브로크백 망원 (리뷰 4개)\n",
            "✅ 저장 성공: 브로크백 망원\n",
            "⏳ 분석 시작: 끄을림 (리뷰 6개)\n",
            "✅ 저장 성공: 끄을림\n",
            "⏳ 분석 시작: 옥수당 망원시장점 (리뷰 2개)\n",
            "✅ 저장 성공: 옥수당 망원시장점\n",
            "⏳ 분석 시작: 자연애곳간 망원시장점 (리뷰 1개)\n",
            "✅ 저장 성공: 자연애곳간 망원시장점\n",
            "⏳ 분석 시작: 돌쇠떡고을 월드컵시장점 (리뷰 7개)\n",
            "✅ 저장 성공: 돌쇠떡고을 월드컵시장점\n",
            "⏳ 분석 시작: 홍어전문점 (리뷰 9개)\n",
            "✅ 저장 성공: 홍어전문점\n",
            "⏳ 분석 시작: 카페인중독 망원점 (리뷰 5개)\n",
            "✅ 저장 성공: 카페인중독 망원점\n",
            "⏳ 분석 시작: 퓸즈 망원점 (리뷰 8개)\n",
            "✅ 저장 성공: 퓸즈 망원점\n",
            "⏳ 분석 시작: 달리는커피 서울망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 달리는커피 서울망원점\n",
            "⏳ 분석 시작: 뉴케이스 망원본점 (리뷰 2개)\n",
            "✅ 저장 성공: 뉴케이스 망원본점\n",
            "⏳ 분석 시작: 투썸플레이스 마포망원점 (리뷰 24개)\n",
            "✅ 저장 성공: 투썸플레이스 마포망원점\n",
            "⏳ 분석 시작: 설빙 서울망원점 (리뷰 19개)\n",
            "✅ 저장 성공: 설빙 서울망원점\n",
            "⏳ 분석 시작: 고망고 망원점 (리뷰 20개)\n",
            "✅ 저장 성공: 고망고 망원점\n",
            "⏳ 분석 시작: 80호 자유 (리뷰 9개)\n",
            "✅ 저장 성공: 80호 자유\n",
            "⏳ 분석 시작: 더파인트 (리뷰 4개)\n",
            "✅ 저장 성공: 더파인트\n",
            "⏳ 분석 시작: 딥블루레이크 (리뷰 100개)\n",
            "✅ 저장 성공: 딥블루레이크\n",
            "⏳ 분석 시작: 키오스크 (리뷰 100개)\n",
            "✅ 저장 성공: 키오스크\n",
            "⏳ 분석 시작: 메가MGC커피 망원망리단길점 (리뷰 12개)\n",
            "✅ 저장 성공: 메가MGC커피 망원망리단길점\n",
            "⏳ 분석 시작: 카페공명 망원책빵 (리뷰 18개)\n",
            "✅ 저장 성공: 카페공명 망원책빵\n",
            "⏳ 분석 시작: 도래노트 (리뷰 44개)\n",
            "✅ 저장 성공: 도래노트\n",
            "⏳ 분석 시작: 꼬르소산도 (리뷰 58개)\n",
            "✅ 저장 성공: 꼬르소산도\n",
            "⏳ 분석 시작: 스타벅스 망원한강공원점 (리뷰 100개)\n",
            "✅ 저장 성공: 스타벅스 망원한강공원점\n",
            "⏳ 분석 시작: 도쿄빙수 본점 (리뷰 100개)\n",
            "✅ 저장 성공: 도쿄빙수 본점\n",
            "⏳ 분석 시작: 모아새 (리뷰 86개)\n",
            "✅ 저장 성공: 모아새\n",
            "⏳ 분석 시작: 두두리두팡 망원본점 (리뷰 32개)\n",
            "✅ 저장 성공: 두두리두팡 망원본점\n",
            "⏳ 분석 시작: 올웨이즈어거스트 (리뷰 100개)\n",
            "✅ 저장 성공: 올웨이즈어거스트\n",
            "⏳ 분석 시작: 아브르드팡 (리뷰 7개)\n",
            "✅ 저장 성공: 아브르드팡\n",
            "⏳ 분석 시작: 스몰커피바 (리뷰 39개)\n",
            "✅ 저장 성공: 스몰커피바\n",
            "⏳ 분석 시작: 레이지독케이크 (리뷰 12개)\n",
            "✅ 저장 성공: 레이지독케이크\n",
            "⏳ 분석 시작: 몬스터스토리지 메종망원점 (리뷰 9개)\n",
            "✅ 저장 성공: 몬스터스토리지 메종망원점\n",
            "⏳ 분석 시작: 어레미 (리뷰 10개)\n",
            "✅ 저장 성공: 어레미\n",
            "⏳ 분석 시작: 해브어 (리뷰 44개)\n",
            "✅ 저장 성공: 해브어\n",
            "⏳ 분석 시작: 포스트노빌즈 (리뷰 61개)\n",
            "✅ 저장 성공: 포스트노빌즈\n",
            "⏳ 분석 시작: 리파인드카페 (리뷰 2개)\n",
            "✅ 저장 성공: 리파인드카페\n",
            "⏳ 분석 시작: 네르 (리뷰 3개)\n",
            "✅ 저장 성공: 네르\n",
            "⏳ 분석 시작: 카페핀드 (리뷰 18개)\n",
            "✅ 저장 성공: 카페핀드\n",
            "⏳ 분석 시작: 카페 고잉홈 (리뷰 34개)\n",
            "✅ 저장 성공: 카페 고잉홈\n",
            "⏳ 분석 시작: 크리머리 (리뷰 19개)\n",
            "✅ 저장 성공: 크리머리\n",
            "⏳ 분석 시작: 평형 (리뷰 54개)\n",
            "✅ 저장 성공: 평형\n",
            "⏳ 분석 시작: 이어케이크 (리뷰 15개)\n",
            "✅ 저장 성공: 이어케이크\n",
            "⏳ 분석 시작: 카페카카 (리뷰 85개)\n",
            "✅ 저장 성공: 카페카카\n",
            "⏳ 분석 시작: 나탈레 (리뷰 2개)\n",
            "✅ 저장 성공: 나탈레\n",
            "⏳ 분석 시작: 메이크베러띵스 (리뷰 52개)\n",
            "✅ 저장 성공: 메이크베러띵스\n",
            "⏳ 분석 시작: 피피커피 (리뷰 100개)\n",
            "✅ 저장 성공: 피피커피\n",
            "⏳ 분석 시작: 라뚜셩트베이커리 (리뷰 53개)\n",
            "✅ 저장 성공: 라뚜셩트베이커리\n",
            "⏳ 분석 시작: 메가MGC커피 마포중앙점 (리뷰 10개)\n",
            "✅ 저장 성공: 메가MGC커피 마포중앙점\n",
            "⏳ 분석 시작: 제로어쎔 (리뷰 4개)\n",
            "✅ 저장 성공: 제로어쎔\n",
            "⏳ 분석 시작: 메가MGC커피 망원시장점 (리뷰 9개)\n",
            "✅ 저장 성공: 메가MGC커피 망원시장점\n",
            "⏳ 분석 시작: 카페 나기 (리뷰 3개)\n",
            "✅ 저장 성공: 카페 나기\n",
            "⏳ 분석 시작: 구황작물 (리뷰 45개)\n",
            "✅ 저장 성공: 구황작물\n",
            "⏳ 분석 시작: 고드니 망원 (리뷰 7개)\n",
            "✅ 저장 성공: 고드니 망원\n",
            "⏳ 분석 시작: 다다랩 (리뷰 86개)\n",
            "✅ 저장 성공: 다다랩\n",
            "⏳ 분석 시작: 프토빌 (리뷰 6개)\n",
            "✅ 저장 성공: 프토빌\n",
            "⏳ 분석 시작: 솔티웨이브 (리뷰 9개)\n",
            "✅ 저장 성공: 솔티웨이브\n",
            "⏳ 분석 시작: 퍼스널커피 (리뷰 39개)\n",
            "✅ 저장 성공: 퍼스널커피\n",
            "⏳ 분석 시작: 버터크림팩토리 (리뷰 58개)\n",
            "✅ 저장 성공: 버터크림팩토리\n",
            "⏳ 분석 시작: 광합성카페 (리뷰 72개)\n",
            "✅ 저장 성공: 광합성카페\n",
            "⏳ 분석 시작: 범골커피 (리뷰 10개)\n",
            "✅ 저장 성공: 범골커피\n",
            "⏳ 분석 시작: 러브레플리카 (리뷰 6개)\n",
            "✅ 저장 성공: 러브레플리카\n",
            "⏳ 분석 시작: Uig (리뷰 86개)\n",
            "✅ 저장 성공: Uig\n",
            "⏳ 분석 시작: 오늘의위로 (리뷰 42개)\n",
            "✅ 저장 성공: 오늘의위로\n",
            "⏳ 분석 시작: 루아르커피바 망원 (리뷰 49개)\n",
            "✅ 저장 성공: 루아르커피바 망원\n",
            "⏳ 분석 시작: 카펫 망원점 (리뷰 62개)\n",
            "✅ 저장 성공: 카펫 망원점\n",
            "⏳ 분석 시작: 카페밤비 2호점 (리뷰 6개)\n",
            "✅ 저장 성공: 카페밤비 2호점\n",
            "⏳ 분석 시작: 마핑파 (리뷰 34개)\n",
            "✅ 저장 성공: 마핑파\n",
            "⏳ 분석 시작: 로트 (리뷰 21개)\n",
            "✅ 저장 성공: 로트\n",
            "⏳ 분석 시작: 찬찬커피로스터스 (리뷰 24개)\n",
            "✅ 저장 성공: 찬찬커피로스터스\n",
            "⏳ 분석 시작: 필리커피 (리뷰 34개)\n",
            "✅ 저장 성공: 필리커피\n",
            "⏳ 분석 시작: 피우커피 (리뷰 9개)\n",
            "✅ 저장 성공: 피우커피\n",
            "⏳ 분석 시작: 씨엘로 (리뷰 13개)\n",
            "✅ 저장 성공: 씨엘로\n",
            "⏳ 분석 시작: 플랩핑커피 (리뷰 7개)\n",
            "✅ 저장 성공: 플랩핑커피\n",
            "⏳ 분석 시작: 센토브 (리뷰 30개)\n",
            "✅ 저장 성공: 센토브\n",
            "⏳ 분석 시작: 빽다방 망원시장점 (리뷰 16개)\n",
            "✅ 저장 성공: 빽다방 망원시장점\n",
            "⏳ 분석 시작: 컴포즈커피 망원시장점 (리뷰 9개)\n",
            "✅ 저장 성공: 컴포즈커피 망원시장점\n",
            "⏳ 분석 시작: 탭커피 망원점 (리뷰 5개)\n",
            "✅ 저장 성공: 탭커피 망원점\n",
            "⏳ 분석 시작: 9램 (리뷰 21개)\n",
            "✅ 저장 성공: 9램\n",
            "⏳ 분석 시작: 보울리 (리뷰 10개)\n",
            "✅ 저장 성공: 보울리\n",
            "⏳ 분석 시작: 레오띠 (리뷰 3개)\n",
            "✅ 저장 성공: 레오띠\n",
            "⏳ 분석 시작: 빽다방 마포시민공원점 (리뷰 7개)\n",
            "✅ 저장 성공: 빽다방 마포시민공원점\n",
            "⏳ 분석 시작: 커피무카24 망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 커피무카24 망원점\n",
            "⏳ 분석 시작: 매머드익스프레스 망원역점 (리뷰 10개)\n",
            "✅ 저장 성공: 매머드익스프레스 망원역점\n",
            "⏳ 분석 시작: 누운 (리뷰 26개)\n",
            "✅ 저장 성공: 누운\n",
            "⏳ 분석 시작: 호버 (리뷰 6개)\n",
            "✅ 저장 성공: 호버\n",
            "⏳ 분석 시작: 베러댄알콜 (리뷰 27개)\n",
            "✅ 저장 성공: 베러댄알콜\n",
            "⏳ 분석 시작: 에그밀 (리뷰 6개)\n",
            "✅ 저장 성공: 에그밀\n",
            "⏳ 분석 시작: 메럴리 (리뷰 20개)\n",
            "✅ 저장 성공: 메럴리\n",
            "⏳ 분석 시작: 무흐 (리뷰 7개)\n",
            "✅ 저장 성공: 무흐\n",
            "⏳ 분석 시작: 닷트 dott (리뷰 13개)\n",
            "✅ 저장 성공: 닷트 dott\n",
            "⏳ 분석 시작: 하우스오브바이닐 망원점 (리뷰 33개)\n",
            "✅ 저장 성공: 하우스오브바이닐 망원점\n",
            "⏳ 분석 시작: 한강에스프레소 (리뷰 100개)\n",
            "✅ 저장 성공: 한강에스프레소\n",
            "⏳ 분석 시작: 페트롤플레이스 (리뷰 51개)\n",
            "✅ 저장 성공: 페트롤플레이스\n",
            "⏳ 분석 시작: 고리 (리뷰 13개)\n",
            "✅ 저장 성공: 고리\n",
            "⏳ 분석 시작: 위트윈스 (리뷰 11개)\n",
            "✅ 저장 성공: 위트윈스\n",
            "⏳ 분석 시작: 딥블루레이크 (리뷰 11개)\n",
            "✅ 저장 성공: 딥블루레이크\n",
            "⏳ 분석 시작: 스테어 (리뷰 4개)\n",
            "✅ 저장 성공: 스테어\n",
            "⏳ 분석 시작: 오렌지페블 (리뷰 29개)\n",
            "✅ 저장 성공: 오렌지페블\n",
            "⏳ 분석 시작: 히피커피 (리뷰 4개)\n",
            "✅ 저장 성공: 히피커피\n",
            "⏳ 분석 시작: 꼬레소레하우스 (리뷰 10개)\n",
            "✅ 저장 성공: 꼬레소레하우스\n",
            "⏳ 분석 시작: 프레피커피랩 망원점 (리뷰 11개)\n",
            "✅ 저장 성공: 프레피커피랩 망원점\n",
            "⏳ 분석 시작: 텀어우드 (리뷰 11개)\n",
            "✅ 저장 성공: 텀어우드\n",
            "⏳ 분석 시작: 카페게이트 망원역점 (리뷰 11개)\n",
            "✅ 저장 성공: 카페게이트 망원역점\n",
            "⏳ 분석 시작: 바나타이거 망원점 (리뷰 13개)\n",
            "✅ 저장 성공: 바나타이거 망원점\n",
            "⏳ 분석 시작: 이호커피 망원점 (리뷰 14개)\n",
            "✅ 저장 성공: 이호커피 망원점\n",
            "⏳ 분석 시작: 인바이트 (리뷰 3개)\n",
            "✅ 저장 성공: 인바이트\n",
            "⏳ 분석 시작: 요거트아이스크림의정석 망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 요거트아이스크림의정석 망원점\n",
            "⏳ 분석 시작: 그냥방실 (리뷰 12개)\n",
            "✅ 저장 성공: 그냥방실\n",
            "⏳ 분석 시작: 요거로밀 (리뷰 12개)\n",
            "✅ 저장 성공: 요거로밀\n",
            "⏳ 분석 시작: 오늘요거 (리뷰 5개)\n",
            "✅ 저장 성공: 오늘요거\n",
            "⏳ 분석 시작: M1CT (리뷰 47개)\n",
            "✅ 저장 성공: M1CT\n",
            "⏳ 분석 시작: 필담 (리뷰 33개)\n",
            "✅ 저장 성공: 필담\n",
            "⏳ 분석 시작: 포트레이트 커피바 (리뷰 100개)\n",
            "✅ 저장 성공: 포트레이트 커피바\n",
            "⏳ 분석 시작: 카페엠 (리뷰 21개)\n",
            "✅ 저장 성공: 카페엠\n",
            "⏳ 분석 시작: 파사도 망원 (리뷰 42개)\n",
            "✅ 저장 성공: 파사도 망원\n",
            "⏳ 분석 시작: 보통공원 (리뷰 50개)\n",
            "✅ 저장 성공: 보통공원\n",
            "⏳ 분석 시작: 코코부코 망원본점 (리뷰 44개)\n",
            "✅ 저장 성공: 코코부코 망원본점\n",
            "⏳ 분석 시작: 604 (리뷰 67개)\n",
            "✅ 저장 성공: 604\n",
            "⏳ 분석 시작: 오탄틱 (리뷰 18개)\n",
            "✅ 저장 성공: 오탄틱\n",
            "⏳ 분석 시작: 숲터 그로브 허브 망원 (리뷰 3개)\n",
            "✅ 저장 성공: 숲터 그로브 허브 망원\n",
            "⏳ 분석 시작: 브라운프론트도어 (리뷰 31개)\n",
            "✅ 저장 성공: 브라운프론트도어\n",
            "⏳ 분석 시작: WHH 와하하 (리뷰 26개)\n",
            "✅ 저장 성공: WHH 와하하\n",
            "⏳ 분석 시작: 카페빈틈m (리뷰 75개)\n",
            "✅ 저장 성공: 카페빈틈m\n",
            "⏳ 분석 시작: 키프키프나인 (리뷰 11개)\n",
            "✅ 저장 성공: 키프키프나인\n",
            "⏳ 분석 시작: 큰새 브루잉 (리뷰 2개)\n",
            "✅ 저장 성공: 큰새 브루잉\n",
            "⏳ 분석 시작: 낫트 (리뷰 4개)\n",
            "✅ 저장 성공: 낫트\n",
            "⏳ 분석 시작: JS라운지 망원점 (리뷰 3개)\n",
            "✅ 저장 성공: JS라운지 망원점\n",
            "⏳ 분석 시작: 망디 (리뷰 9개)\n",
            "✅ 저장 성공: 망디\n",
            "⏳ 분석 시작: 이롭커피베이크 (리뷰 11개)\n",
            "✅ 저장 성공: 이롭커피베이크\n",
            "⏳ 분석 시작: 커차그 (리뷰 12개)\n",
            "✅ 저장 성공: 커차그\n",
            "⏳ 분석 시작: 타티커피스 (리뷰 3개)\n",
            "✅ 저장 성공: 타티커피스\n",
            "⏳ 분석 시작: HHSS하우스 (리뷰 40개)\n",
            "✅ 저장 성공: HHSS하우스\n",
            "⏳ 분석 시작: 파동로스터리카페 (리뷰 2개)\n",
            "✅ 저장 성공: 파동로스터리카페\n",
            "⏳ 분석 시작: 메가MGC커피 마포시민공원점 (리뷰 12개)\n",
            "✅ 저장 성공: 메가MGC커피 마포시민공원점\n",
            "⏳ 분석 시작: 시모어 (리뷰 20개)\n",
            "✅ 저장 성공: 시모어\n",
            "⏳ 분석 시작: 카페기글 (리뷰 11개)\n",
            "✅ 저장 성공: 카페기글\n",
            "⏳ 분석 시작: 메가MGC커피 망원포은점 (리뷰 2개)\n",
            "✅ 저장 성공: 메가MGC커피 망원포은점\n",
            "⏳ 분석 시작: 소피 (리뷰 19개)\n",
            "✅ 저장 성공: 소피\n",
            "⏳ 분석 시작: 사과당 망원점 (리뷰 4개)\n",
            "✅ 저장 성공: 사과당 망원점\n",
            "⏳ 분석 시작: 도파민 (리뷰 22개)\n",
            "✅ 저장 성공: 도파민\n",
            "⏳ 분석 시작: 카나모노룸 (리뷰 26개)\n",
            "✅ 저장 성공: 카나모노룸\n",
            "⏳ 분석 시작: 허니빙스 (리뷰 16개)\n",
            "✅ 저장 성공: 허니빙스\n",
            "⏳ 분석 시작: 마르뜨 (리뷰 16개)\n",
            "✅ 저장 성공: 마르뜨\n",
            "⏳ 분석 시작: 할루 (리뷰 4개)\n",
            "✅ 저장 성공: 할루\n",
            "⏳ 분석 시작: 우지커피 망원한강공원점 (리뷰 16개)\n",
            "✅ 저장 성공: 우지커피 망원한강공원점\n",
            "⏳ 분석 시작: 달보드레 (리뷰 5개)\n",
            "✅ 저장 성공: 달보드레\n",
            "⏳ 분석 시작: 커넥츠커피 망원점 (리뷰 53개)\n",
            "✅ 저장 성공: 커넥츠커피 망원점\n",
            "⏳ 분석 시작: 카페텅 망원점 (리뷰 10개)\n",
            "✅ 저장 성공: 카페텅 망원점\n",
            "⏳ 분석 시작: 지누스 (리뷰 9개)\n",
            "✅ 저장 성공: 지누스\n",
            "⏳ 분석 시작: 구스커피앤바 (리뷰 46개)\n",
            "✅ 저장 성공: 구스커피앤바\n",
            "⏳ 분석 시작: 틸다운 망원 (리뷰 7개)\n",
            "✅ 저장 성공: 틸다운 망원\n",
            "⏳ 분석 시작: 카페하임 (리뷰 17개)\n",
            "✅ 저장 성공: 카페하임\n",
            "⏳ 분석 시작: 애독의흔적 (리뷰 1개)\n",
            "✅ 저장 성공: 애독의흔적\n",
            "⏳ 분석 시작: 노웨어홈 (리뷰 11개)\n",
            "✅ 저장 성공: 노웨어홈\n",
            "⏳ 분석 시작: 큐엔에이룸 (리뷰 4개)\n",
            "✅ 저장 성공: 큐엔에이룸\n",
            "⏳ 분석 시작: 캐롤라인더스틴 (리뷰 2개)\n",
            "✅ 저장 성공: 캐롤라인더스틴\n",
            "⏳ 분석 시작: 피에스타7커피 망리단길점 (리뷰 6개)\n",
            "✅ 저장 성공: 피에스타7커피 망리단길점\n",
            "⏳ 분석 시작: 이디야커피 망리단길점 (리뷰 14개)\n",
            "✅ 저장 성공: 이디야커피 망리단길점\n",
            "⏳ 분석 시작: 페이브커피 망원시장점 (리뷰 3개)\n",
            "✅ 저장 성공: 페이브커피 망원시장점\n",
            "⏳ 분석 시작: 오슬로우 월드컵시장점 (리뷰 1개)\n",
            "✅ 저장 성공: 오슬로우 월드컵시장점\n",
            "⏳ 분석 시작: 모을 (리뷰 53개)\n",
            "✅ 저장 성공: 모을\n",
            "⏳ 분석 시작: 힙댕 (리뷰 16개)\n",
            "✅ 저장 성공: 힙댕\n",
            "⏳ 분석 시작: 루틸 (리뷰 15개)\n",
            "✅ 저장 성공: 루틸\n",
            "⏳ 분석 시작: 아더커피 망원점 (리뷰 1개)\n",
            "✅ 저장 성공: 아더커피 망원점\n",
            "⏳ 분석 시작: 삼공 (리뷰 21개)\n",
            "✅ 저장 성공: 삼공\n"
          ]
        }
      ],
      "source": [
        "# # 5. 실행 루프\n",
        "# final_reports = []\n",
        "# if os.path.exists(checkpoint_path):\n",
        "#     with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "#         final_reports = json.load(f)\n",
        "# analyzed_ids = {str(r.get('store_id')) for r in final_reports}\n",
        "\n",
        "# for sid in df['ID'].unique():\n",
        "#     if str(sid) in analyzed_ids: continue\n",
        "\n",
        "#     s_df = df[df['ID'] == sid]\n",
        "#     s_info = s_df.iloc[0]\n",
        "\n",
        "#     # 리뷰가 150개 이상이면 최신순/랜덤으로 100개만 샘플링 (속도 및 메모리 보호)\n",
        "#     r_list = s_df['종합리뷰'].dropna().tolist()\n",
        "#     if len(r_list) > 100:\n",
        "#         r_list = r_list[:100]\n",
        "\n",
        "#     print(f\"⏳ 분석 시작: {s_info['식당명']} (리뷰 {len(r_list)}개)\")\n",
        "\n",
        "#     report = generate_and_verify_report(s_info, r_list, 0.7)\n",
        "\n",
        "#     if report:\n",
        "#         final_reports.append(report)\n",
        "#         with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "#             json.dump(final_reports, f, ensure_ascii=False, indent=4)\n",
        "#         print(f\"✅ 저장 성공: {s_info['식당명']}\")\n",
        "\n",
        "#     torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "블로그 데이터 1차 추가"
      ],
      "metadata": {
        "id": "ihVoeSIpRSC1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Eh-0GVVBhoj",
        "outputId": "595cc346-0d13-4bd7-8fd1-0c9f68f1e1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 블로그 데이터 로드 완료: 112개 식당\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 로드\n",
        "json_path = os.path.join(base_path, 'NaverMap_Final_Extracted.json')\n",
        "with open(json_path, 'r', encoding='utf-8') as f:\n",
        "    blog_data = json.load(f)\n",
        "\n",
        "# 2. 블로그 데이터를 담을 리스트 (기존 df와 유사한 구조로 생성)\n",
        "blog_rows = []\n",
        "for store in blog_data:\n",
        "    store_name = store.get('Name')\n",
        "    # 식당별로 여러 명이 쓴 리뷰들을 리스트로 수집\n",
        "    reviews = [rev.get('Content', '') for rev in store.get('Reviews', []) if rev.get('Content')]\n",
        "\n",
        "    if reviews:\n",
        "        blog_rows.append({\n",
        "            'ID': f\"BLOG_{store_name}\", # ID가 없는 블로그용 임시 ID\n",
        "            '장소명': store_name,\n",
        "            '리뷰리스트': reviews\n",
        "        })\n",
        "\n",
        "print(f\"✅ 블로그 데이터 로드 완료: {len(blog_rows)}개 식당\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0jI4AHWBw3_",
        "outputId": "4f0b696a-2084-44ad-e1e2-88d699b52874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ 블로그 분석 시작: 초월양곱창 (ID: 1134437672, 리뷰 2개)\n",
            "✅ 저장 완료: 초월양곱창\n",
            "⏳ 블로그 분석 시작: 키친갈매기 (ID: 1373294203, 리뷰 2개)\n",
            "✅ 저장 완료: 키친갈매기\n",
            "⏳ 블로그 분석 시작: 오시 망원본점 (ID: 863823354, 리뷰 3개)\n",
            "✅ 저장 완료: 오시 망원본점\n",
            "⏳ 블로그 분석 시작: 정든그릇 망원점 (ID: 192598815, 리뷰 3개)\n",
            "✅ 저장 완료: 정든그릇 망원점\n",
            "⏳ 블로그 분석 시작: 다이치 (ID: 396604563, 리뷰 3개)\n",
            "✅ 저장 완료: 다이치\n",
            "⏳ 블로그 분석 시작: 티노마드모리 (ID: 1546506535, 리뷰 2개)\n",
            "✅ 저장 완료: 티노마드모리\n",
            "⏳ 블로그 분석 시작: 벚꽃스시 망원점 (ID: 690650568, 리뷰 3개)\n",
            "✅ 저장 완료: 벚꽃스시 망원점\n",
            "⏳ 블로그 분석 시작: 설경 (ID: 1673857593, 리뷰 3개)\n",
            "✅ 저장 완료: 설경\n",
            "⏳ 블로그 분석 시작: 고양꼬치 마포구청점 (ID: 946372629, 리뷰 3개)\n",
            "✅ 저장 완료: 고양꼬치 마포구청점\n",
            "⏳ 블로그 분석 시작: 무어스 (ID: 805235919, 리뷰 3개)\n",
            "✅ 저장 완료: 무어스\n",
            "⏳ 블로그 분석 시작: 유어다이닝 (ID: 1594402645, 리뷰 2개)\n",
            "✅ 저장 완료: 유어다이닝\n",
            "⏳ 블로그 분석 시작: 웨얼이즈누들 (ID: 612300151, 리뷰 3개)\n",
            "✅ 저장 완료: 웨얼이즈누들\n",
            "⏳ 블로그 분석 시작: 노모어피자 마포구청점 (ID: 988313618, 리뷰 3개)\n",
            "✅ 저장 완료: 노모어피자 마포구청점\n",
            "⏳ 블로그 분석 시작: 논드라이 (ID: 213806746, 리뷰 3개)\n",
            "✅ 저장 완료: 논드라이\n",
            "⏳ 블로그 분석 시작: 쿠루리 (ID: 770918827, 리뷰 3개)\n",
            "✅ 저장 완료: 쿠루리\n",
            "⏳ 블로그 분석 시작: 선데이카리오카 (ID: 2127662487, 리뷰 3개)\n",
            "✅ 저장 완료: 선데이카리오카\n",
            "⏳ 블로그 분석 시작: 라오삐약 (ID: 539411343, 리뷰 2개)\n",
            "✅ 저장 완료: 라오삐약\n",
            "⏳ 블로그 분석 시작: 망원갈매기 (ID: 1206453002, 리뷰 3개)\n",
            "✅ 저장 완료: 망원갈매기\n",
            "⏳ 블로그 분석 시작: 육회바른연어 망원시장점 (ID: 2011961596, 리뷰 3개)\n",
            "✅ 저장 완료: 육회바른연어 망원시장점\n",
            "⏳ 블로그 분석 시작: 피자먹다 망원점 (ID: 114090745, 리뷰 2개)\n",
            "✅ 저장 완료: 피자먹다 망원점\n",
            "⏳ 블로그 분석 시작: 큐스닭강정 (ID: 19949548, 리뷰 2개)\n",
            "✅ 저장 완료: 큐스닭강정\n",
            "⏳ 블로그 분석 시작: 장터국밥 (ID: 1637957216, 리뷰 2개)\n",
            "✅ 저장 완료: 장터국밥\n",
            "⏳ 블로그 분석 시작: 그리드 망원 (ID: 333525317, 리뷰 3개)\n",
            "✅ 저장 완료: 그리드 망원\n",
            "⏳ 블로그 분석 시작: 코우콘 (ID: 1996288682, 리뷰 2개)\n",
            "✅ 저장 완료: 코우콘\n",
            "⏳ 블로그 분석 시작: 선술집 순 (ID: 218205521, 리뷰 3개)\n",
            "✅ 저장 완료: 선술집 순\n",
            "⏳ 블로그 분석 시작: 앗츠 (ID: 1819829977, 리뷰 3개)\n",
            "✅ 저장 완료: 앗츠\n",
            "⏳ 블로그 분석 시작: 해물장수 (ID: 677182056, 리뷰 3개)\n",
            "✅ 저장 완료: 해물장수\n",
            "⏳ 블로그 분석 시작: 망원곱창시장 (ID: 407097008, 리뷰 3개)\n",
            "✅ 저장 완료: 망원곱창시장\n",
            "⏳ 블로그 분석 시작: 땅스부대찌개 망원월드컵시장점 (ID: 1907652089, 리뷰 2개)\n",
            "✅ 저장 완료: 땅스부대찌개 망원월드컵시장점\n",
            "⏳ 블로그 분석 시작: 망원동숯불족발보쌈 (ID: 155788758, 리뷰 1개)\n",
            "✅ 저장 완료: 망원동숯불족발보쌈\n",
            "⏳ 블로그 분석 시작: 투다리 망원1점 (ID: 19493745, 리뷰 3개)\n",
            "✅ 저장 완료: 투다리 망원1점\n",
            "⏳ 블로그 분석 시작: 달래식탁 (ID: 1722816819, 리뷰 3개)\n",
            "✅ 저장 완료: 달래식탁\n",
            "⏳ 블로그 분석 시작: 쪼지네술방 (ID: 1962111749, 리뷰 3개)\n",
            "✅ 저장 완료: 쪼지네술방\n",
            "⏳ 블로그 분석 시작: 샐리스 팜투테이블 망원 (ID: 762144078, 리뷰 3개)\n",
            "✅ 저장 완료: 샐리스 팜투테이블 망원\n",
            "⏳ 블로그 분석 시작: 도담 (ID: 608684968, 리뷰 3개)\n",
            "✅ 저장 완료: 도담\n",
            "⏳ 블로그 분석 시작: 망원돈 (ID: 1261558408, 리뷰 3개)\n",
            "✅ 저장 완료: 망원돈\n",
            "⏳ 블로그 분석 시작: 산수냉면 망원점 (ID: 864560292, 리뷰 2개)\n",
            "✅ 저장 완료: 산수냉면 망원점\n",
            "⏳ 블로그 분석 시작: 보리 (ID: 1465610622, 리뷰 2개)\n",
            "✅ 저장 완료: 보리\n",
            "⏳ 블로그 분석 시작: 하심정 (ID: 11246724, 리뷰 3개)\n",
            "✅ 저장 완료: 하심정\n",
            "⏳ 블로그 분석 시작: 세이슈 (ID: 955690982, 리뷰 3개)\n",
            "✅ 저장 완료: 세이슈\n",
            "⏳ 블로그 분석 시작: 슌우 (ID: 1845595908, 리뷰 2개)\n",
            "✅ 저장 완료: 슌우\n",
            "⏳ 블로그 분석 시작: 정주일가 (ID: 1683571681, 리뷰 3개)\n",
            "✅ 저장 완료: 정주일가\n",
            "⏳ 블로그 분석 시작: 온리디스베이커리 (ID: 436819496, 리뷰 3개)\n",
            "✅ 저장 완료: 온리디스베이커리\n",
            "⏳ 블로그 분석 시작: 해피박스 (ID: 1074062572, 리뷰 2개)\n",
            "✅ 저장 완료: 해피박스\n",
            "⏳ 블로그 분석 시작: 픽셀 (ID: 636287285, 리뷰 3개)\n",
            "✅ 저장 완료: 픽셀\n",
            "⏳ 블로그 분석 시작: 트릴토리 (ID: 340970062, 리뷰 3개)\n",
            "✅ 저장 완료: 트릴토리\n",
            "⏳ 블로그 분석 시작: 명랑핫도그 망원역점 (ID: 660959515, 리뷰 3개)\n",
            "✅ 저장 완료: 명랑핫도그 망원역점\n",
            "⏳ 블로그 분석 시작: 이웃집통통이 망원점 (ID: 1411066687, 리뷰 3개)\n",
            "✅ 저장 완료: 이웃집통통이 망원점\n",
            "⏳ 블로그 분석 시작: 리브인오후 (ID: 86103478, 리뷰 2개)\n",
            "✅ 저장 완료: 리브인오후\n",
            "⏳ 블로그 분석 시작: 1994양과점 (ID: 205941174, 리뷰 3개)\n",
            "✅ 저장 완료: 1994양과점\n",
            "⏳ 블로그 분석 시작: 바이어리셔 (ID: 577707896, 리뷰 2개)\n",
            "✅ 저장 완료: 바이어리셔\n",
            "⏳ 블로그 분석 시작: 스위즈 (ID: 1170755892, 리뷰 3개)\n",
            "✅ 저장 완료: 스위즈\n",
            "⏳ 블로그 분석 시작: 마로스베이크하우스 (ID: 281609941, 리뷰 3개)\n",
            "✅ 저장 완료: 마로스베이크하우스\n",
            "⏳ 블로그 분석 시작: 다시점 (ID: 1760178156, 리뷰 3개)\n",
            "✅ 저장 완료: 다시점\n",
            "⏳ 블로그 분석 시작: 스트릿츄러스 한강버스망원점 (ID: 1218219193, 리뷰 1개)\n",
            "✅ 저장 완료: 스트릿츄러스 한강버스망원점\n",
            "⏳ 블로그 분석 시작: 콜린 (ID: 78638994, 리뷰 3개)\n",
            "✅ 저장 완료: 콜린\n",
            "⏳ 블로그 분석 시작: 망원도 (ID: 1088931092, 리뷰 3개)\n",
            "✅ 저장 완료: 망원도\n",
            "⏳ 블로그 분석 시작: 아루감 (ID: 1559821182, 리뷰 3개)\n",
            "✅ 저장 완료: 아루감\n",
            "⏳ 블로그 분석 시작: 시우 (ID: 2100908584, 리뷰 3개)\n",
            "✅ 저장 완료: 시우\n",
            "⏳ 블로그 분석 시작: 반달포차 (ID: 1237404281, 리뷰 3개)\n",
            "✅ 저장 완료: 반달포차\n",
            "⏳ 블로그 분석 시작: 올위크 (ID: 1550572588, 리뷰 3개)\n",
            "✅ 저장 완료: 올위크\n",
            "⏳ 블로그 분석 시작: 차차 (ID: 186054313, 리뷰 2개)\n",
            "✅ 저장 완료: 차차\n",
            "⏳ 블로그 분석 시작: 파운드마켓 망원점 (ID: 1442818966, 리뷰 3개)\n",
            "✅ 저장 완료: 파운드마켓 망원점\n",
            "⏳ 블로그 분석 시작: 리벌티 망원 (ID: 2130305474, 리뷰 3개)\n",
            "✅ 저장 완료: 리벌티 망원\n",
            "⏳ 블로그 분석 시작: 스몰굿커피 망원역점 (ID: 1516145205, 리뷰 3개)\n",
            "✅ 저장 완료: 스몰굿커피 망원역점\n",
            "⏳ 블로그 분석 시작: 레코드시즌 (ID: 1419333748, 리뷰 3개)\n",
            "✅ 저장 완료: 레코드시즌\n",
            "⏳ 블로그 분석 시작: 고체 (ID: 1324444548, 리뷰 3개)\n",
            "✅ 저장 완료: 고체\n",
            "⏳ 블로그 분석 시작: 딜리커피 망원 (ID: 966218107, 리뷰 3개)\n",
            "✅ 저장 완료: 딜리커피 망원\n",
            "⏳ 블로그 분석 시작: 히카 (ID: 1243515681, 리뷰 3개)\n",
            "✅ 저장 완료: 히카\n",
            "⏳ 블로그 분석 시작: 플로어 망원 (ID: 277085613, 리뷰 3개)\n",
            "✅ 저장 완료: 플로어 망원\n",
            "⏳ 블로그 분석 시작: 콘웰 (ID: 1909653777, 리뷰 3개)\n",
            "✅ 저장 완료: 콘웰\n",
            "⏳ 블로그 분석 시작: 메가MGC커피 망원역점 (ID: 239288973, 리뷰 3개)\n",
            "✅ 저장 완료: 메가MGC커피 망원역점\n",
            "⏳ 블로그 분석 시작: 락떼스피릿 (ID: 267155694, 리뷰 2개)\n",
            "✅ 저장 완료: 락떼스피릿\n",
            "⏳ 블로그 분석 시작: 망원 지튼 (ID: 1536487352, 리뷰 3개)\n",
            "✅ 저장 완료: 망원 지튼\n",
            "\n",
            "==================================================\n",
            "📊 최종 분석 정산 리포트\n",
            "1. 성공적으로 분석된 식당: 74개\n",
            "2. 매핑 파일(CSV)에서 ID를 찾지 못한 식당: 55개\n",
            "   - 누락 목록: 무어스플라워, 조선화로구이, 그리드디자인랩, 식해 한식바다주점, 이자카야 촌, 얼쑤 망원, 청어람 망원본점, 팜풀, 서교주담 망원, 서교주담 합정...\n",
            "3. 모델 분석 과정에서 실패한 식당: 0개\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# 1. 환경 설정 및 데이터 로드\n",
        "checkpoint_path = os.path.join(base_path, 'mangwon_blog_report.json')\n",
        "mapped_df = pd.read_csv(os.path.join(base_path, 'mangwon_mapped_v2.csv'), encoding='cp949')\n",
        "\n",
        "with open(os.path.join(base_path, 'NaverMap_Final_Extracted.json'), 'r', encoding='utf-8-sig') as f:\n",
        "    blog_data = json.load(f)\n",
        "\n",
        "# 2. 기존 결과 로드 및 분석 완료 ID 파악\n",
        "final_reports = []\n",
        "if os.path.exists(checkpoint_path):\n",
        "    with open(checkpoint_path, 'r', encoding='utf-8-sig') as f:\n",
        "        final_reports = json.load(f)\n",
        "analyzed_ids = {str(r.get('store_id')) for r in final_reports}\n",
        "\n",
        "# 3. 분석 루프 및 결과 수집\n",
        "not_found_in_mapping = []  # 매핑 파일에 이름이 없는 경우\n",
        "analysis_failed = []      # 모델 분석 중 에러난 경우\n",
        "\n",
        "for store in blog_data:\n",
        "    raw_name = store.get('Name')\n",
        "\n",
        "    # [ID 매칭 로직] mapped_df에서 해당 식당의 ID 찾기\n",
        "    # 양쪽 공백 제거 및 완전 일치 기준 (필요시 str.contains 사용 가능)\n",
        "    match = mapped_df[mapped_df['장소명'].str.strip() == raw_name.strip()]\n",
        "\n",
        "    if match.empty:\n",
        "        not_found_in_mapping.append(raw_name)\n",
        "        continue\n",
        "\n",
        "    sid = str(match.iloc[0]['ID'])\n",
        "    real_name = match.iloc[0]['장소명'] # 매핑된 공식 명칭 사용\n",
        "\n",
        "    # 이미 분석했다면 스킵\n",
        "    if sid in analyzed_ids:\n",
        "        continue\n",
        "\n",
        "    # 여러 사람이 쓴 리뷰 리스트화\n",
        "    r_list = [rev.get('Content', '') for rev in store.get('Reviews', []) if rev.get('Content')]\n",
        "\n",
        "    # 데이터가 아예 없는 경우 스킵\n",
        "    if not r_list:\n",
        "        continue\n",
        "\n",
        "    # 리뷰가 너무 많으면 100개 샘플링 (기존 로직 유지)\n",
        "    if len(r_list) > 100:\n",
        "        r_list = r_list[:100]\n",
        "\n",
        "    print(f\"⏳ 블로그 분석 시작: {real_name} (ID: {sid}, 리뷰 {len(r_list)}개)\")\n",
        "\n",
        "    # 기존 함수 그대로 호출 (s_info 형식 맞춰서 전달)\n",
        "    s_info = {'ID': sid, '장소명': real_name}\n",
        "    report = generate_and_verify_report(s_info, r_list, 0.7)\n",
        "\n",
        "    if report:\n",
        "        final_reports.append(report)\n",
        "        # 실시간 저장 (체크포인트)\n",
        "        with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(final_reports, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"✅ 저장 완료: {real_name}\")\n",
        "    else:\n",
        "        analysis_failed.append(real_name)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# 4. 최종 분석 현황 리포트\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"📊 최종 분석 정산 리포트\")\n",
        "print(f\"1. 성공적으로 분석된 식당: {len(final_reports)}개\")\n",
        "print(f\"2. 매핑 파일(CSV)에서 ID를 찾지 못한 식당: {len(not_found_in_mapping)}개\")\n",
        "if not_found_in_mapping:\n",
        "    print(f\"   - 누락 목록: {', '.join(not_found_in_mapping[:10])}...\")\n",
        "print(f\"3. 모델 분석 과정에서 실패한 식당: {len(analysis_failed)}개\")\n",
        "if analysis_failed:\n",
        "    print(f\"   - 실패 목록: {', '.join(analysis_failed)}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjbsUQ42GttL"
      },
      "source": [
        "중복ID 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APSm2IyaGqe9",
        "outputId": "26fbc167-ad8b-44c2-d9f2-996cc400bc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "🔍 리포트 간 중복 식당 확인 (총 5개)\n",
            "--------------------------------------------------\n",
            "        ID             식당명\n",
            "  11246724             하심정\n",
            "2100908584              시우\n",
            "1907652089 땅스부대찌개 망원월드컵시장점\n",
            "1559821182             아루감\n",
            "1088931092             망원도\n",
            "--------------------------------------------------\n",
            "💡 팁: 중복된 식당은 일반 리뷰와 블로그 데이터가 모두 존재합니다.\n",
            "최종 합본을 만들 때 '리뷰 개수가 더 많은 쪽'을 선택하거나 데이터를 병합할 수 있습니다.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_only_reviews_report.json')\n",
        "mapped_csv_path = os.path.join(base_path, 'mangwon_mapped_v2.csv')\n",
        "\n",
        "# 2. 리포트 로드 및 ID-이름 매핑 생성 함수\n",
        "def get_report_dict(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
        "            data = json.load(f)\n",
        "            # {ID: 식당명} 딕셔너리 생성\n",
        "            return {str(item.get('store_id')): item.get('store_name') for item in data}\n",
        "    return {}\n",
        "\n",
        "# 3. 데이터 로드\n",
        "blog_dict = get_report_dict(blog_report_path)\n",
        "review_dict = get_report_dict(review_report_path)\n",
        "mapped_df = pd.read_csv(mapped_csv_path, encoding='cp949')\n",
        "\n",
        "# 4. 중복 ID 찾기 (교집합)\n",
        "duplicate_ids = set(blog_dict.keys()) & set(review_dict.keys())\n",
        "\n",
        "# 5. 결과 출력\n",
        "print(\"=\"*50)\n",
        "print(f\"🔍 리포트 간 중복 식당 확인 (총 {len(duplicate_ids)}개)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if not duplicate_ids:\n",
        "    print(\"중복된 식당 ID가 없습니다.\")\n",
        "else:\n",
        "    # 중복된 식당의 ID와 이름을 표 형태로 출력\n",
        "    dup_list = []\n",
        "    for sid in duplicate_ids:\n",
        "        # 블로그 리포트나 리뷰 리포트 중 이름이 있는 곳에서 가져옴\n",
        "        name = blog_dict.get(sid) or review_dict.get(sid)\n",
        "        dup_list.append({'ID': sid, '식당명': name})\n",
        "\n",
        "    df_dup = pd.DataFrame(dup_list)\n",
        "    print(df_dup.to_string(index=False))\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"💡 팁: 중복된 식당은 일반 리뷰와 블로그 데이터가 모두 존재합니다.\")\n",
        "print(\"최종 합본을 만들 때 '리뷰 개수가 더 많은 쪽'을 선택하거나 데이터를 병합할 수 있습니다.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfqG3DN1GzuG"
      },
      "source": [
        "누락ID 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HevTwYMiG1GH",
        "outputId": "10e55a74-4368-49b8-9e4b-a62c27313600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "📊 분석 결과 통합 및 누락 확인\n",
            "1. 블로그 리포트 ID 개수: 74개\n",
            "2. 일반 리뷰 리포트 ID 개수: 650개\n",
            "3. 중복 제외 통합 분석 완료 ID: 719개\n",
            "4. mapped_v2.csv 전체 식당 개수: 756개\n",
            "--------------------------------------------------\n",
            "⚠️ 누락된 식당 발견: 37개\n",
            "📍 누락된 식당 목록 (상위 10개):\n",
            "   - ID: 1100082903 | 이름: 바삭마차 망원본점\n",
            "   - ID: 2119780640 | 이름: 게뜨망하우스\n",
            "   - ID: 1063033896 | 이름: 어수선회&초밥\n",
            "   - ID: 65852876 | 이름: BBQ 한강버스망원선착장점\n",
            "   - ID: 211364003 | 이름: 불만있는치킨\n",
            "   - ID: 93122129 | 이름: 망원장터국밥\n",
            "   - ID: 2098634499 | 이름: 식해\n",
            "   - ID: 1873776 | 이름: 촌\n",
            "   - ID: 684089354 | 이름: 얼쑤\n",
            "   - ID: 1065846269 | 이름: 본가안동찜닭닭도리탕\n",
            "   - ID: 1997011697 | 이름: 황제정육식당&수제돼지갈비\n",
            "   - ID: 1374582458 | 이름: 구구족 망원점\n",
            "   - ID: 1535960191 | 이름: 서교주담 망원점\n",
            "   - ID: 1639736108 | 이름: 망원리 황태 콩나물해장국\n",
            "   - ID: 1075250749 | 이름: 노가리랑닭발\n",
            "   - ID: 27336512 | 이름: 샘밭골\n",
            "   - ID: 2032582194 | 이름: 대장군부속구이\n",
            "   - ID: 1128510180 | 이름: 타코장인24시\n",
            "   - ID: 1691318306 | 이름: 더바이글\n",
            "   - ID: 911552927 | 이름: 디망쉬키친\n",
            "   - ID: 1879823956 | 이름: 마닐다과\n",
            "   - ID: 308774273 | 이름: 밀리언스\n",
            "   - ID: 117343217 | 이름: 이자카야제때 망원점\n",
            "   - ID: 1748676286 | 이름: 글래스트레인\n",
            "   - ID: 1575163805 | 이름: 망원옥상\n",
            "   - ID: 1005785183 | 이름: 망원술집\n",
            "   - ID: 1448010208 | 이름: 시우\n",
            "   - ID: 8014880 | 이름: 오시오\n",
            "   - ID: 1229061292 | 이름: okens Seoul 망원 익스프레스\n",
            "   - ID: 1558684636 | 이름: 얼라이브214\n",
            "   - ID: 2111985961 | 이름: 제로투원카페\n",
            "   - ID: 2028626364 | 이름: 나우올네버 now oR never\n",
            "   - ID: 2129652732 | 이름: 카페게이트 망원한강점\n",
            "   - ID: 1996118092 | 이름: 낮도깨비밤도깨비\n",
            "   - ID: 616856088 | 이름: 프뤼떼마지\n",
            "   - ID: 380173059 | 이름: 허니빙스 호두사랑\n",
            "   - ID: 630795566 | 이름: 고미푸딩\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_only_reviews_report.json')\n",
        "mapped_csv_path = os.path.join(base_path, 'mangwon_mapped_v2.csv')\n",
        "\n",
        "# 2. 리포트 데이터 로드 함수\n",
        "def load_json_ids(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            # 각 리포트의 store_id를 추출 (문자열로 통일)\n",
        "            return {str(item.get('store_id')) for item in data}\n",
        "    return set()\n",
        "\n",
        "# 3. 데이터 불러오기\n",
        "blog_ids = load_json_ids(blog_report_path)\n",
        "review_ids = load_json_ids(review_report_path)\n",
        "mapped_df = pd.read_csv(mapped_csv_path, encoding='cp949')\n",
        "\n",
        "# 4. ID 통합 및 중복 제거\n",
        "# 두 리포트에 모두 있는 식당도 있으므로 합집합(union)을 구합니다.\n",
        "total_analyzed_ids = blog_ids | review_ids\n",
        "all_mapped_ids = set(mapped_df['ID'].astype(str).unique())\n",
        "\n",
        "# 5. 결과 계산\n",
        "intersect_ids = total_analyzed_ids & all_mapped_ids  # 실제로 매핑 파일에 존재하는 분석된 ID\n",
        "missing_ids = all_mapped_ids - total_analyzed_ids     # 매핑 파일에는 있지만 리포트에는 없는 ID\n",
        "\n",
        "# 6. 리포트 출력\n",
        "print(\"=\"*50)\n",
        "print(\"📊 분석 결과 통합 및 누락 확인\")\n",
        "print(f\"1. 블로그 리포트 ID 개수: {len(blog_ids)}개\")\n",
        "print(f\"2. 일반 리뷰 리포트 ID 개수: {len(review_ids)}개\")\n",
        "print(f\"3. 중복 제외 통합 분석 완료 ID: {len(total_analyzed_ids)}개\")\n",
        "print(f\"4. mapped_v2.csv 전체 식당 개수: {len(all_mapped_ids)}개\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if len(missing_ids) == 0:\n",
        "    print(\"✅ 축하합니다! 모든 식당(ID)이 리포트에 포함되어 있습니다.\")\n",
        "else:\n",
        "    print(f\"⚠️ 누락된 식당 발견: {len(missing_ids)}개\")\n",
        "    print(\"📍 누락된 식당 목록 (상위 10개):\")\n",
        "    # 누락된 ID의 실제 이름을 확인하기 위해 다시 매핑\n",
        "    missing_names = mapped_df[mapped_df['ID'].astype(str).isin(missing_ids)][['ID', '장소명']]\n",
        "    for _, row in missing_names.iterrows():\n",
        "        print(f\"   - ID: {row['ID']} | 이름: {row['장소명']}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrdpujvRIVJi"
      },
      "source": [
        "병합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4mhtbE_IV9A",
        "outputId": "0b2d9997-dae1-4718-8eff-57a3da5ce2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "✅ Kakao 일반 리뷰 우선 병합 완료\n",
            "- 총 통합 식당 개수: 719개\n",
            "- 중복되어 Kakao로 덮어쓴 식당: 5개\n",
            "- 블로그 데이터로만 채워진 식당: 69개\n",
            "--------------------------------------------------\n",
            "📍 저장 위치: /content/drive/MyDrive/likelion-khai/mangwon_final_integrated_report.json\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_only_reviews_report.json')\n",
        "final_merge_path = os.path.join(base_path, 'mangwon_final_integrated_report.json')\n",
        "\n",
        "# 2. 데이터 로드\n",
        "def load_json(path):\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "blog_data = load_json(blog_report_path)\n",
        "review_data = load_json(review_report_path)\n",
        "\n",
        "# 3. 병합 전략 수행 (Kakao 우선)\n",
        "merged_dict = {}\n",
        "\n",
        "# [Step 1] 블로그 데이터를 먼저 채우기\n",
        "for report in blog_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# [Step 2] Kakao 일반 리뷰 데이터로 덮어쓰기 (중복 시 Kakao가 최종본이 됨)\n",
        "duplicate_count = 0\n",
        "for report in review_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "\n",
        "    if sid in merged_dict:\n",
        "        # 이미 블로그 데이터가 있는 경우 Kakao로 교체\n",
        "        duplicate_count += 1\n",
        "        # 필요하다면 여기서 어떤 데이터가 교체되는지 로그를 남길 수 있습니다.\n",
        "\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# 4. 리스트로 변환 및 최종 저장\n",
        "final_integrated_list = list(merged_dict.values())\n",
        "\n",
        "with open(final_merge_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_integrated_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 5. 최종 결과 확인\n",
        "print(\"=\"*50)\n",
        "print(\"✅ Kakao 일반 리뷰 우선 병합 완료\")\n",
        "print(f\"- 총 통합 식당 개수: {len(final_integrated_list)}개\")\n",
        "print(f\"- 중복되어 Kakao로 덮어쓴 식당: {duplicate_count}개\")\n",
        "print(f\"- 블로그 데이터로만 채워진 식당: {len(blog_data) - duplicate_count}개\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"📍 저장 위치: {final_merge_path}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "블로그 데이터 2차 추가"
      ],
      "metadata": {
        "id": "E9QaGwlnRWDE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHgdDi1h8dbI",
        "outputId": "e795f454-2548-4a25-d74d-637746e5e89a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 매칭 성공: 장터국밥 (ID: 1637957216, 리뷰 2개)\n",
            "✅ 매칭 성공: 식해 한식바다주점 (ID: 2098634499, 리뷰 2개)\n",
            "✅ 매칭 성공: 이자카야 촌 (ID: 1873776, 리뷰 3개)\n",
            "✅ 매칭 성공: 얼쑤 망원 (ID: 684089354, 리뷰 3개)\n",
            "✅ 매칭 성공: 황제정육식당&수제돼지갈비 (ID: 1997011697, 리뷰 1개)\n",
            "✅ 매칭 성공: 서교주담 망원 (ID: 1535960191, 리뷰 3개)\n",
            "✅ 매칭 성공: 더 바이글 (ID: 1691318306, 리뷰 2개)\n",
            "✅ 매칭 성공: 디망쉬 키친 (ID: 911552927, 리뷰 3개)\n",
            "✅ 매칭 성공: 마닐다과 화과자공방 (ID: 1879823956, 리뷰 3개)\n",
            "✅ 매칭 성공: 이자카야 제때 망원점 (ID: 117343217, 리뷰 2개)\n",
            "✅ 매칭 성공: Alive214 (ID: 1558684636, 리뷰 2개)\n",
            "✅ 매칭 성공: 나우올네버 (ID: 2028626364, 리뷰 3개)\n",
            "✅ 매칭 성공: 낮도깨비 밤도깨비 (ID: 1996118092, 리뷰 2개)\n",
            "✅ 매칭 성공: 프뤼떼마지 본점작업실 (ID: 616856088, 리뷰 3개)\n",
            "✅ 매칭 성공: 고미푸딩 망원점 (ID: 630795566, 리뷰 3개)\n",
            "\n",
            "==================================================\n",
            "📊 추출 완료 리포트\n",
            "1. 리뷰가 포함된 식당 개수: 15개\n",
            "2. CSV 매핑에 실패한 식당 개수: 28개\n",
            "📍 저장 위치: /content/drive/MyDrive/likelion-khai/mangwon_blog_extracted_reviews.json\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 경로 설정\n",
        "# base_path = \"본인의 경로로 설정하세요\"\n",
        "checkpoint_path = os.path.join(base_path, 'mangwon_blog_extracted_reviews.json')\n",
        "csv_path = os.path.join(base_path, 'check_list.csv')\n",
        "json_input_path = os.path.join(base_path, 'ch2.json')\n",
        "\n",
        "# 2. 데이터 로드\n",
        "# ID가 지수표기법으로 변하지 않도록 문자열(str)로 읽기\n",
        "mapped_df = pd.read_csv(csv_path, encoding='cp949', dtype={'ID': str})\n",
        "\n",
        "with open(json_input_path, 'r', encoding='utf-8-sig') as f:\n",
        "    blog_data = json.load(f)\n",
        "\n",
        "# 3. 데이터 매칭 및 추출\n",
        "extracted_results = []\n",
        "not_found_count = 0\n",
        "\n",
        "for store in blog_data:\n",
        "    raw_name = (store.get('Name') or \"\").strip()\n",
        "\n",
        "    # [매칭 로직] CSV의 'Name' 컬럼과 json의 'Name'이 일치하는 행 찾기\n",
        "    match = mapped_df[mapped_df['Name'].str.strip() == raw_name]\n",
        "\n",
        "    # 직접 일치가 없으면 SearchKeyword로 한 번 더 확인 (유연한 매칭)\n",
        "    if match.empty:\n",
        "        match = mapped_df[mapped_df['SearchKeyword'].str.contains(raw_name, na=False) if raw_name else False]\n",
        "\n",
        "    if not match.empty:\n",
        "        sid = str(match.iloc[0]['ID'])\n",
        "        real_name = match.iloc[0]['Name']\n",
        "\n",
        "        # 리뷰 리스트 추출 (내용이 있는 것만)\n",
        "        r_list = [rev.get('Content', '') for rev in store.get('Reviews', []) if rev.get('Content')]\n",
        "\n",
        "        if r_list:\n",
        "            extracted_results.append({\n",
        "                \"store_id\": sid,\n",
        "                \"store_name\": real_name,\n",
        "                \"address\": match.iloc[0]['Address'],\n",
        "                \"reviews\": r_list\n",
        "            })\n",
        "            print(f\"✅ 매칭 성공: {real_name} (ID: {sid}, 리뷰 {len(r_list)}개)\")\n",
        "    else:\n",
        "        not_found_count += 1\n",
        "\n",
        "# 4. 결과 저장\n",
        "with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(extracted_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 5. 최종 결과 확인\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"📊 추출 완료 리포트\")\n",
        "print(f\"1. 리뷰가 포함된 식당 개수: {len(extracted_results)}개\")\n",
        "print(f\"2. CSV 매핑에 실패한 식당 개수: {not_found_count}개\")\n",
        "print(f\"📍 저장 위치: {checkpoint_path}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StnwlbSvAN1v",
        "outputId": "5b594f6c-ce13-4868-abea-a0b153746c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 매칭 성공: 장터국밥 <- 장터국밥 (Score: 1.20)\n",
            "🎯 매칭 성공: 식해 한식바다주점 <- 식해 한식바다주점 (Score: 1.20)\n",
            "🎯 매칭 성공: 이자카야 촌 <- 이자카야 촌 (Score: 1.20)\n",
            "🎯 매칭 성공: 얼쑤 망원 <- 얼쑤 망원 (Score: 1.20)\n",
            "🎯 매칭 성공: 황제정육식당&수제돼지갈비 <- 황제정육식당&수제돼지갈비 (Score: 1.20)\n",
            "🎯 매칭 성공: 서교주담 망원 <- 서교주담 망원 (Score: 1.20)\n",
            "🎯 매칭 성공: 더 바이글 <- 더 바이글 (Score: 1.20)\n",
            "🎯 매칭 성공: 디망쉬 키친 <- 디망쉬 키친 (Score: 1.20)\n",
            "🎯 매칭 성공: 마닐다과 화과자공방 <- 마닐다과 화과자공방 (Score: 1.20)\n",
            "🎯 매칭 성공: 이자카야 제때 망원점 <- 이자카야 제때 망원점 (Score: 1.20)\n",
            "🎯 매칭 성공: Alive214 <- Alive214 (Score: 1.20)\n",
            "🎯 매칭 성공: 나우올네버 <- 나우올네버 (Score: 1.20)\n",
            "🎯 매칭 성공: 낮도깨비 밤도깨비 <- 낮도깨비 밤도깨비 (Score: 1.20)\n",
            "🎯 매칭 성공: 프뤼떼마지 본점작업실 <- 프뤼떼마지 본점작업실 (Score: 1.20)\n",
            "🎯 매칭 성공: 고미푸딩 망원점 <- 고미푸딩 망원점 (Score: 1.20)\n",
            "\n",
            "==================================================\n",
            "📊 최종 추출 결과\n",
            "- 타겟 식당 수: 23개\n",
            "- 실제 매칭 및 리뷰 추출 성공: 15개\n",
            "- 누락된 식당: ['망원리황태콩나물해장국', '오시오', '오켄스서울 망원익스프레스', '샘밭골', '망원옥상', '카페게이트 망원한강점', '대장군 부속구이', '구구족 망원점']\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# 유사도 계산 함수 (0~1 사이 점수)\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# 1. 파일 로드\n",
        "csv_path = os.path.join(base_path, 'check_list.csv')\n",
        "json_input_path = os.path.join(base_path, 'ch2.json')\n",
        "output_path = os.path.join(base_path, 'mangwon_final_extracted_reviews.json')\n",
        "\n",
        "mapped_df = pd.read_csv(csv_path, encoding='cp949', dtype={'ID': str})\n",
        "with open(json_input_path, 'r', encoding='utf-8-sig') as f:\n",
        "    blog_data = json.load(f)\n",
        "\n",
        "final_extracted = []\n",
        "matched_ids = set()\n",
        "\n",
        "# 2. 매칭 로직 (CSV 기준 루프 - 23개를 다 채우기 위함)\n",
        "for _, row in mapped_df.iterrows():\n",
        "    target_id = str(row['ID'])\n",
        "    target_name = str(row['Name']).strip()\n",
        "    search_key = str(row['SearchKeyword']).strip()\n",
        "\n",
        "    best_match_store = None\n",
        "    max_score = 0\n",
        "\n",
        "    for store in blog_data:\n",
        "        json_name = (store.get('Name') or \"\").strip()\n",
        "\n",
        "        # 이름 유사도 측정 (예: '장터국밥' vs '망원장터국밥')\n",
        "        score = similarity(target_name, json_name)\n",
        "\n",
        "        # 포함 관계일 경우 가점 (예: '식해' vs '식해 한식바다주점')\n",
        "        if target_name in json_name or json_name in target_name:\n",
        "            score += 0.2\n",
        "\n",
        "        if score > max_score:\n",
        "            max_score = score\n",
        "            best_match_store = store\n",
        "\n",
        "    # 점수가 0.6 이상인 경우에만 매칭 성공으로 간주\n",
        "    if max_score >= 0.6 and best_match_store:\n",
        "        reviews = [rev.get('Content', '') for rev in best_match_store.get('Reviews', []) if rev.get('Content')]\n",
        "\n",
        "        if reviews:\n",
        "            final_extracted.append({\n",
        "                \"store_id\": target_id,\n",
        "                \"store_name\": target_name,\n",
        "                \"naver_match_name\": best_match_store.get('Name'),\n",
        "                \"reviews\": reviews\n",
        "            })\n",
        "            matched_ids.add(target_id)\n",
        "            print(f\"🎯 매칭 성공: {target_name} <- {best_match_store.get('Name')} (Score: {max_score:.2f})\")\n",
        "\n",
        "# 3. 결과 저장\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_extracted, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 4. 최종 정산\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"📊 최종 추출 결과\")\n",
        "print(f\"- 타겟 식당 수: {len(mapped_df)}개\")\n",
        "print(f\"- 실제 매칭 및 리뷰 추출 성공: {len(final_extracted)}개\")\n",
        "if len(mapped_df) > len(final_extracted):\n",
        "    missing = set(mapped_df['Name']) - {x['store_name'] for x in final_extracted}\n",
        "    print(f\"- 누락된 식당: {list(missing)}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7skwtQ40J4x3",
        "outputId": "f065bd78-b181-4246-d98f-d742730eb135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ 분석 시작: 장터국밥 (ID: 93122129, 매칭명: 장터국밥, 리뷰 2개)\n",
            "✅ 저장 성공: 장터국밥\n",
            "\n",
            "==================================================\n",
            "📊 최종 분석 완료: 총 16개 리포트 생성\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# 1. 경로 설정 (사용자 환경에 맞게 수정)\n",
        "# base_path = \"/content/drive/MyDrive/...\"\n",
        "checkpoint_path = os.path.join(base_path, 'mangwon_blog_report2.json')\n",
        "csv_path = os.path.join(base_path, 'check_list.csv')\n",
        "json_input_path = os.path.join(base_path, 'ch2.json')\n",
        "\n",
        "# 2. 데이터 로드 및 초기화\n",
        "# ID를 문자열로 읽어 지수 표기법 방지\n",
        "mapped_df = pd.read_csv(csv_path, encoding='cp949', dtype={'ID': str})\n",
        "with open(json_input_path, 'r', encoding='utf-8-sig') as f:\n",
        "    blog_data = json.load(f)\n",
        "\n",
        "# 기존 분석 결과 로드 (중복 분석 방지)\n",
        "final_reports = []\n",
        "if os.path.exists(checkpoint_path):\n",
        "    with open(checkpoint_path, 'r', encoding='utf-8-sig') as f:\n",
        "        final_reports = json.load(f)\n",
        "analyzed_ids = {str(r.get('store_id')) for r in final_reports}\n",
        "\n",
        "# 3. 유사도 매칭 함수 (가점 포함)\n",
        "def get_similarity(target, source):\n",
        "    t_clean = str(target).replace(\" \", \"\")\n",
        "    s_clean = str(source).replace(\" \", \"\")\n",
        "    score = SequenceMatcher(None, t_clean, s_clean).ratio()\n",
        "    if t_clean in s_clean or s_clean in t_clean:\n",
        "        score += 0.2\n",
        "    return score\n",
        "\n",
        "# 4. 분석 루프 실행\n",
        "# CSV에 명시된 23개 타겟 식당을 기준으로 순회\n",
        "for _, row in mapped_df.iterrows():\n",
        "    sid = str(row['ID'])\n",
        "    target_name = str(row['Name']).strip()\n",
        "\n",
        "    # 이미 분석된 ID는 스킵\n",
        "    if sid in analyzed_ids:\n",
        "        continue\n",
        "\n",
        "    # [매칭 로직] ch2.json 내에서 최적의 식당 찾기\n",
        "    best_match_store = None\n",
        "    max_score = 0\n",
        "\n",
        "    for store in blog_data:\n",
        "        json_name = (store.get('Name') or \"\").strip()\n",
        "        score = get_similarity(target_name, json_name)\n",
        "\n",
        "        if score > max_score:\n",
        "            max_score = score\n",
        "            best_match_store = store\n",
        "\n",
        "    # 임계값 0.7 이상인 경우에만 분석 진행\n",
        "    if max_score >= 0.7 and best_match_store:\n",
        "        # 리뷰 리스트 추출 (Content가 있는 항목만)\n",
        "        r_list = [rev.get('Content', '') for rev in best_match_store.get('Reviews', []) if rev.get('Content')]\n",
        "\n",
        "        if not r_list:\n",
        "            continue\n",
        "\n",
        "        # 리뷰 샘플링 (최대 100개 제한)\n",
        "        if len(r_list) > 100:\n",
        "            r_list = r_list[:100]\n",
        "\n",
        "        print(f\"⏳ 분석 시작: {target_name} (ID: {sid}, 매칭명: {best_match_store.get('Name')}, 리뷰 {len(r_list)}개)\")\n",
        "\n",
        "        # 기존 제공된 분석 함수 호출\n",
        "        s_info = {'ID': sid, '장소명': target_name}\n",
        "        report = generate_and_verify_report(s_info, r_list, 0.7)\n",
        "\n",
        "        if report:\n",
        "            # store_id를 명시적으로 저장하여 일치성 보장\n",
        "            report['store_id'] = sid\n",
        "            final_reports.append(report)\n",
        "\n",
        "            # 분석마다 실시간 저장 (체크포인트 저장)\n",
        "            with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(final_reports, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "            analyzed_ids.add(sid)\n",
        "            print(f\"✅ 저장 성공: {target_name}\")\n",
        "        else:\n",
        "            print(f\"❌ 분석 실패/반환값 없음: {target_name}\")\n",
        "\n",
        "        # GPU 메모리 관리\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"📊 최종 분석 완료: 총 {len(final_reports)}개 리포트 생성\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m65SBttIKZ4W",
        "outputId": "0a1db1c4-245b-4671-8a42-705f32fbe1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "✅ Kakao 일반 리뷰 우선 병합 완료\n",
            "- 총 통합 식당 개수: 734개\n",
            "- 중복되어 Kakao로 덮어쓴 식당: 1개\n",
            "- 블로그 데이터로만 채워진 식당: 15개\n",
            "--------------------------------------------------\n",
            "📍 저장 위치: /content/drive/MyDrive/likelion-khai/mangwon_final_final_integrated_report.json\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report2.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_final_integrated_report.json')\n",
        "final_merge_path = os.path.join(base_path, 'mangwon_final_final_integrated_report.json')\n",
        "\n",
        "# 2. 데이터 로드\n",
        "def load_json(path):\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "blog_data = load_json(blog_report_path)\n",
        "review_data = load_json(review_report_path)\n",
        "\n",
        "# 3. 병합 전략 수행 (Kakao 우선)\n",
        "merged_dict = {}\n",
        "\n",
        "# [Step 1] 블로그 데이터를 먼저 채우기\n",
        "for report in blog_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# [Step 2] Kakao 일반 리뷰 데이터로 덮어쓰기 (중복 시 Kakao가 최종본이 됨)\n",
        "duplicate_count = 0\n",
        "for report in review_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "\n",
        "    if sid in merged_dict:\n",
        "        # 이미 블로그 데이터가 있는 경우 Kakao로 교체\n",
        "        duplicate_count += 1\n",
        "        # 필요하다면 여기서 어떤 데이터가 교체되는지 로그를 남길 수 있습니다.\n",
        "\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# 4. 리스트로 변환 및 최종 저장\n",
        "final_integrated_list = list(merged_dict.values())\n",
        "\n",
        "with open(final_merge_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_integrated_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 5. 최종 결과 확인\n",
        "print(\"=\"*50)\n",
        "print(\"✅ Kakao 일반 리뷰 우선 병합 완료\")\n",
        "print(f\"- 총 통합 식당 개수: {len(final_integrated_list)}개\")\n",
        "print(f\"- 중복되어 Kakao로 덮어쓴 식당: {duplicate_count}개\")\n",
        "print(f\"- 블로그 데이터로만 채워진 식당: {len(blog_data) - duplicate_count}개\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"📍 저장 위치: {final_merge_path}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXMWxcTBPMi5",
        "outputId": "482f2f86-5b8d-4512-c7f2-0d134e8229b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "🕵️ 중복 식당 상세 확인 (총 1건)\n",
            "ID              | 식당명                  | 처리 내용\n",
            "------------------------------------------------------------\n",
            "1637957216      | 장터국밥                 | Overwrite (Blog -> Kakao)\n",
            "------------------------------------------------------------\n",
            "✅ 최종 통합 식당 수: 734개\n",
            "💡 블로그 전용 데이터: 15개\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# 1. 파일 경로 (제공해주신 경로 유지)\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report2.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_final_integrated_report.json')\n",
        "final_merge_path = os.path.join(base_path, 'mangwon_final_final_integrated_report.json')\n",
        "\n",
        "# 2. 데이터 로드\n",
        "blog_data = load_json(blog_report_path)\n",
        "review_data = load_json(review_report_path)\n",
        "\n",
        "merged_dict = {}\n",
        "conflict_log = [] # 중복 데이터를 추적할 리스트\n",
        "\n",
        "# [Step 1] 블로그 데이터를 먼저 채우기\n",
        "for report in blog_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# [Step 2] Kakao 리뷰 데이터로 덮어쓰며 중복 확인\n",
        "duplicate_count = 0\n",
        "for report in review_data:\n",
        "    sid = str(report.get('store_id'))\n",
        "    s_name = report.get('store_name', 'Unknown')\n",
        "\n",
        "    if sid in merged_dict:\n",
        "        # 중복 발생 시 로그 기록\n",
        "        conflict_log.append({\n",
        "            \"ID\": sid,\n",
        "            \"Name\": s_name,\n",
        "            \"Action\": \"Overwrite (Blog -> Kakao)\",\n",
        "            \"Blog_Review_Count\": len(merged_dict[sid].get('top_keywords', [])), # 비교용 예시 데이터\n",
        "            \"Kakao_Review_Count\": len(report.get('top_keywords', []))\n",
        "        })\n",
        "        duplicate_count += 1\n",
        "\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# 3. 최종 저장\n",
        "final_integrated_list = list(merged_dict.values())\n",
        "with open(final_merge_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_integrated_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 4. 중복 리스트 상세 출력\n",
        "print(\"=\"*60)\n",
        "print(f\"🕵️ 중복 식당 상세 확인 (총 {duplicate_count}건)\")\n",
        "print(f\"{'ID':<15} | {'식당명':<20} | {'처리 내용'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for log in conflict_log:\n",
        "    print(f\"{log['ID']:<15} | {log['Name']:<20} | {log['Action']}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"✅ 최종 통합 식당 수: {len(final_integrated_list)}개\")\n",
        "print(f\"💡 블로그 전용 데이터: {len(blog_data) - duplicate_count}개\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ7zLzA4Pxsg",
        "outputId": "62fef79e-8e87-487e-dd40-6940829820d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "✅ ID 기반 독립 병합 완료\n",
            "- 최종 파일 내 식당 총 개수: 733개\n",
            "- 실제 ID가 충돌하여 덮어쓴 식당: 1개\n",
            "  (충돌 목록: ['장터국밥(1637957216)'])\n",
            "------------------------------------------------------------\n",
            "💡 확인: 이제 ID 93122129와 1637957216은 별개의 데이터로 보존됩니다.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report2.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_final_integrated_report.json')\n",
        "final_merge_path = os.path.join(base_path, 'mangwon_final_final_integrated_report.json')\n",
        "\n",
        "def load_json(path):\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "# 2. 데이터 로드\n",
        "blog_data = load_json(blog_report_path)\n",
        "review_data = load_json(review_report_path)\n",
        "\n",
        "# 3. 병합 전략 (ID가 다르면 무조건 유지)\n",
        "merged_dict = {}\n",
        "\n",
        "# [Step 1] 블로그 데이터 먼저 등록 (93122129 포함)\n",
        "for report in blog_data:\n",
        "    sid = str(report.get('store_id')).strip()\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# [Step 2] 기존 통합 데이터 등록 (1637957216 포함)\n",
        "collision_count = 0\n",
        "collision_names = []\n",
        "\n",
        "for report in review_data:\n",
        "    sid = str(report.get('store_id')).strip()\n",
        "    s_name = report.get('store_name', 'Unknown')\n",
        "\n",
        "    # ID가 완전히 똑같은 경우만 중복으로 처리\n",
        "    if sid in merged_dict:\n",
        "        collision_count += 1\n",
        "        collision_names.append(f\"{s_name}({sid})\")\n",
        "        # 중복 ID일 경우 기존 데이터를 유지할지, 새 데이터를 덮어쓸지 결정\n",
        "        # 여기서는 Kakao 우선 원칙에 따라 덮어씁니다.\n",
        "        merged_dict[sid] = report\n",
        "    else:\n",
        "        # ID가 다르면 이름이 같아도 새로운 항목으로 추가됨\n",
        "        merged_dict[sid] = report\n",
        "\n",
        "# 4. 결과 저장\n",
        "final_integrated_list = list(merged_dict.values())\n",
        "with open(final_merge_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_integrated_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# 5. 결과 확인\n",
        "print(\"=\"*60)\n",
        "print(f\"✅ ID 기반 독립 병합 완료\")\n",
        "print(f\"- 최종 파일 내 식당 총 개수: {len(final_integrated_list)}개\")\n",
        "print(f\"- 실제 ID가 충돌하여 덮어쓴 식당: {collision_count}개\")\n",
        "if collision_names:\n",
        "    print(f\"  (충돌 목록: {collision_names})\")\n",
        "print(\"-\" * 60)\n",
        "print(\"💡 확인: 이제 ID 93122129와 1637957216은 별개의 데이터로 보존됩니다.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhZtpjA3P-Ip",
        "outputId": "d475d577-8735-431e-b890-64ef8bbc2909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "📊 최종 병합 정산\n",
            "- ID 93122129 (망원장터국밥) 존재 여부: 미존재 (실패)\n",
            "- ID 1637957216 (장터국밥) 존재 여부: 존재 (성공)\n",
            "- 총 통합 식당 수: 733개\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 데이터 로드\n",
        "csv_path = os.path.join(base_path, 'check_list.csv')\n",
        "blog_report_path = os.path.join(base_path, 'mangwon_blog_report2.json')\n",
        "review_report_path = os.path.join(base_path, 'mangwon_final_integrated_report.json')\n",
        "final_merge_path = os.path.join(base_path, 'mangwon_final_final_integrated_report.json')\n",
        "\n",
        "# CSV 로드 (이름-ID 매핑용)\n",
        "mapped_df = pd.read_csv(csv_path, encoding='cp949', dtype={'ID': str})\n",
        "name_to_id = dict(zip(mapped_df['Name'].str.strip(), mapped_df['ID']))\n",
        "\n",
        "def load_json(path):\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r', encoding='utf-8-sig') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "blog_data = load_json(blog_report_path)\n",
        "review_data = load_json(review_report_path)\n",
        "\n",
        "merged_dict = {}\n",
        "\n",
        "# [Step 1] 블로그 데이터 처리 (ID가 없으면 CSV에서 찾아 부여)\n",
        "for report in blog_data:\n",
        "    raw_name = report.get('store_name', '').strip()\n",
        "\n",
        "    # ID 찾기: 1. 기존 store_id 확인 -> 2. CSV 매핑 확인\n",
        "    sid = str(report.get('store_id', ''))\n",
        "    if not sid or sid == 'None' or sid == '':\n",
        "        sid = name_to_id.get(raw_name, \"UNKNOWN\")\n",
        "\n",
        "    if sid != \"UNKNOWN\":\n",
        "        report['store_id'] = sid # ID 강제 주입\n",
        "        merged_dict[sid] = report\n",
        "        if sid == \"93122129\":\n",
        "            print(f\"✅ 망원장터국밥(93122129) 데이터 식별 및 ID 부여 성공!\")\n",
        "\n",
        "# [Step 2] 기존 Kakao 데이터 병합 (중복 시 Kakao 우선)\n",
        "for report in review_data:\n",
        "    sid = str(report.get('store_id')).strip()\n",
        "    merged_dict[sid] = report\n",
        "\n",
        "# [Step 3] 최종 저장\n",
        "final_integrated_list = list(merged_dict.values())\n",
        "with open(final_merge_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_integrated_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# [Step 4] 최종 검증\n",
        "final_ids = {str(item.get('store_id')) for item in final_integrated_list}\n",
        "target_id = \"93122129\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"📊 최종 병합 정산\")\n",
        "print(f\"- ID {target_id} (망원장터국밥) 존재 여부: {'존재 (성공)' if target_id in final_ids else '미존재 (실패)'}\")\n",
        "print(f\"- ID 1637957216 (장터국밥) 존재 여부: {'존재 (성공)' if '1637957216' in final_ids else '미존재 (실패)'}\")\n",
        "print(f\"- 총 통합 식당 수: {len(final_integrated_list)}개\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "AmHwwFj1DR0H",
        "outputId": "cda0321c-24c2-4c27-bf62-320e99e413bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실제 전화번호가 중복된 매장 건수: 6개\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    print(f\\\"\\uc624\\ub958\\uac00 \\ubc1c\\uc0dd\\ud588\\uc2b5\\ub2c8\\ub2e4: {e}\\\")\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\uc7a5\\uc18c\\uba85\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\uad11\",\n          \"\\uad11\\ucc38\\uce58\",\n          \"\\uc5b4\\uc218\\uc120\\ud68c&\\ucd08\\ubc25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc804\\ud654\\ubc88\\ud638\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"02-3143-6949\",\n          \"02-322-8762\",\n          \"02-332-2979\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc8fc\\uc18c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\uc11c\\uc6b8 \\ub9c8\\ud3ec\\uad6c \\ub9dd\\uc6d0\\ub3d9 414-20\",\n          \"\\uc11c\\uc6b8 \\ub9c8\\ud3ec\\uad6c \\ub9dd\\uc6d0\\ub3d9 485-2\",\n          \"\\uc11c\\uc6b8 \\ub9c8\\ud3ec\\uad6c \\ub9dd\\uc6d0\\ub3d9 475-51\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uce74\\ud14c\\uace0\\ub9ac\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\uc74c\\uc2dd\\uc810 > \\uc77c\\uc2dd > \\ucc38\\uce58\\ud68c\",\n          \"\\uc74c\\uc2dd\\uc810 > \\ud55c\\uc2dd > \\uad6d\\uc218 > \\uce7c\\uad6d\\uc218\",\n          \"\\uc74c\\uc2dd\\uc810 > \\ud55c\\uc2dd > \\ud574\\ubb3c,\\uc0dd\\uc120 > \\ud68c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fdb46d26-d883-4f38-b03b-0e287d7c069a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>장소명</th>\n",
              "      <th>전화번호</th>\n",
              "      <th>주소</th>\n",
              "      <th>카테고리</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>광</td>\n",
              "      <td>02-3143-6949</td>\n",
              "      <td>서울 마포구 망원동 475-51</td>\n",
              "      <td>음식점 &gt; 일식 &gt; 참치회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>광참치</td>\n",
              "      <td>02-3143-6949</td>\n",
              "      <td>서울 마포구 망원동 475-51</td>\n",
              "      <td>음식점 &gt; 일식 &gt; 참치회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>고향집</td>\n",
              "      <td>02-322-8762</td>\n",
              "      <td>서울 마포구 망원동 414-20</td>\n",
              "      <td>음식점 &gt; 한식 &gt; 국수 &gt; 칼국수</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>고향집칼국수</td>\n",
              "      <td>02-322-8762</td>\n",
              "      <td>서울 마포구 망원동 414-67</td>\n",
              "      <td>음식점 &gt; 한식 &gt; 국수 &gt; 칼국수</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>어수선</td>\n",
              "      <td>02-332-2979</td>\n",
              "      <td>서울 마포구 망원동 485-2</td>\n",
              "      <td>음식점 &gt; 한식 &gt; 해물,생선 &gt; 회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>어수선회&amp;초밥</td>\n",
              "      <td>02-332-2979</td>\n",
              "      <td>서울 마포구 망원동 485-2</td>\n",
              "      <td>음식점 &gt; 한식 &gt; 해물,생선 &gt; 회</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdb46d26-d883-4f38-b03b-0e287d7c069a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdb46d26-d883-4f38-b03b-0e287d7c069a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdb46d26-d883-4f38-b03b-0e287d7c069a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         장소명          전화번호                 주소                  카테고리\n",
              "78         광  02-3143-6949  서울 마포구 망원동 475-51        음식점 > 일식 > 참치회\n",
              "84       광참치  02-3143-6949  서울 마포구 망원동 475-51        음식점 > 일식 > 참치회\n",
              "5        고향집   02-322-8762  서울 마포구 망원동 414-20   음식점 > 한식 > 국수 > 칼국수\n",
              "292   고향집칼국수   02-322-8762  서울 마포구 망원동 414-67   음식점 > 한식 > 국수 > 칼국수\n",
              "8        어수선   02-332-2979   서울 마포구 망원동 485-2  음식점 > 한식 > 해물,생선 > 회\n",
              "216  어수선회&초밥   02-332-2979   서울 마포구 망원동 485-2  음식점 > 한식 > 해물,생선 > 회"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 1. 파일 경로 설정\n",
        "file_path = '/content/drive/MyDrive/likelion-khai/mangwon_mapped_v3.csv'\n",
        "\n",
        "try:\n",
        "    # 2. 데이터 불러오기\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # 3. 데이터 필터링 (비어있는 값 + '없음' 텍스트 제외)\n",
        "    # 실제 전화번호가 있는 행만 남깁니다.\n",
        "    df_filtered = df.dropna(subset=['전화번호']).copy()\n",
        "\n",
        "    # '없음' 문자열과 공백을 모두 제외합니다.\n",
        "    df_filtered = df_filtered[\n",
        "        (df_filtered['전화번호'].str.strip() != '없음') &\n",
        "        (df_filtered['전화번호'].str.strip() != '')\n",
        "    ]\n",
        "\n",
        "    # 4. 필터링된 데이터 중에서 전화번호 중복 추출\n",
        "    duplicates = df_filtered[df_filtered.duplicated(subset=['전화번호'], keep=False)]\n",
        "\n",
        "    # 5. 보기 좋게 정렬\n",
        "    duplicates = duplicates.sort_values(by='전화번호')\n",
        "\n",
        "    # 6. 결과 출력\n",
        "    if not duplicates.empty:\n",
        "        print(f\"실제 전화번호가 중복된 매장 건수: {len(duplicates)}개\")\n",
        "        display(duplicates[['장소명', '전화번호', '주소', '카테고리']])\n",
        "    else:\n",
        "        print(\"전화번호가 기재된 매장 중 중복된 데이터가 없습니다.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"오류가 발생했습니다: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmdJkSuYKnh2",
        "outputId": "c9088611-f5f4-4721-cad5-cf3981a88547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "이전 매장 수: 734\n",
            "삭제된 매장 수: 3\n",
            "현재 매장 수: 731\n",
            "삭제 완료: [1737054562, 415316901, 1543003311]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 파일 경로\n",
        "json_path = '/content/drive/MyDrive/likelion-khai/mangwon_final_final_integrated_report.json'\n",
        "\n",
        "with open(json_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 삭제할 ID 리스트 (숫자형으로 입력)\n",
        "ids_to_remove = [1737054562, 415316901, 1543003311]\n",
        "\n",
        "# 1. 데이터 필터링 (키 이름을 store_id로 지정)\n",
        "original_count = len(data)\n",
        "\n",
        "# 숫자/문자열 상관없이 store_id가 일치하면 제외\n",
        "filtered_data = [\n",
        "    item for item in data\n",
        "    if item.get('store_id') not in ids_to_remove and str(item.get('store_id')) not in map(str, ids_to_remove)\n",
        "]\n",
        "\n",
        "new_count = len(filtered_data)\n",
        "\n",
        "# 2. 결과 저장\n",
        "with open(json_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(filtered_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"이전 매장 수: {original_count}\")\n",
        "print(f\"삭제된 매장 수: {original_count - new_count}\")\n",
        "print(f\"현재 매장 수: {new_count}\")\n",
        "print(f\"삭제 완료: {ids_to_remove}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyM+QTpGp200MbZ6QHAmNobG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}